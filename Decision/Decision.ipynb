{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import predict\n",
    "from sentence_encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded, label_scale, aspects = predict.prepare_data('../../data/iclr_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (papers, paper obj, review, no.reviews, reviews, decision), aspects_score = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_dev, y_dev,x_test, y_test = data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_paper = x_train[0]\n",
    "x_review = x_train[4]\n",
    "# x_num_reviews = x_train[3]\n",
    "x_decision = x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_paper = x_dev[0]\n",
    "d_review = x_dev[4]\n",
    "# d_num_reviews = x_dev[3]\n",
    "d_decision = x_dev[5]\n",
    "\n",
    "t_paper = x_test[0]\n",
    "t_review = x_test[4]\n",
    "# t_num_reviews = x_test[3]\n",
    "t_decision = x_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp_acl = xtacl[0]\n",
    "# tr_acl = xtacl[4]\n",
    "# td_acl = xtacl[5]\n",
    "\n",
    "# dp_acl = xdacl[0]\n",
    "# dr_acl = xdacl[4]\n",
    "# dd_acl = xdacl[5]\n",
    "\n",
    "# cp_acl = tacl[0]\n",
    "# cr_acl = tacl[4]\n",
    "# cd_acl = tacl[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    papers, reviews, decision = data \n",
    "    reviews_embedded = embed(reviews)\n",
    "    papers_embedded = embed(papers)\n",
    "    sentiment_scores = sentiment(reviews)\n",
    "    #papers_embedded = np.repeat(papers_embedded, num_reviews, axis = 0)\n",
    "    decision = np.array(decision).astype(int)\n",
    "    #decision = np.repeat(decision, num_reviews, axis = 0)\n",
    "    return papers_embedded, reviews_embedded, sentiment_scores, decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train, reviews_train, sentiment_train, decision_train = get_data((x_paper, x_review, x_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_train, reviews_train, sentiment_train, decision_train):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_valid, reviews_valid, sentiment_valid, decision_valid = get_data((d_paper, d_review, d_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_valid, reviews_valid, sentiment_valid, decision_valid):\n",
    "    print i.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train = np.pad(papers_train, [(0,0),(0, 1494-666), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_valid = papers_valid[:,:1494,:]\n",
    "reviews_valid = np.pad(reviews_valid, [(0,0),(0, 525-318), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentiment_valid = np.pad(sentiment_valid, [(0,0),(0, 525-318), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_valid, reviews_valid, sentiment_valid, decision_valid):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_test, reviews_test, sentiment_test, decision_test = get_data((t_paper, t_review, t_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_test, reviews_test, sentiment_test, decision_test):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_test = np.pad(papers_test, [(0,0),(0, 1494-419), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "reviews_test = np.pad(reviews_test, [(0,0),(0, 525-309), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentiment_test = np.pad(sentiment_test, [(0,0),(0, 525-309), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iclr-2018 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICLR-2018\n",
    "#### 573 Rejected 336 Accepted Papers, 909 Papers, 2741 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded_, label_scale_, aspects_ = predict1.prepare_data('../../data/iclr_2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (papers, paper obj, review, no.reviews, reviews, decision), aspects_score = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = []\n",
    "for paper in data_padded_[0][1]:\n",
    "    decision.append(paper.__dict__['ACCEPTED'])\n",
    "decision = np.array(decision).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_, ytrain_ = data_padded_\n",
    "papers_, _,_,_,reviews_,decision_ = train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec, review_vec, sentic_vec, dcsn_vec = get_data((papers_[:500], reviews_[:500], decision_[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_vec, review_vec, sentic_vec, dcsn_vec):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec1, review_vec1, sentic_vec1, dcsn_vec1 = get_data((papers_[500:], reviews_[500:], decision_[500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_vec1, review_vec1, sentic_vec1, dcsn_vec1):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_paper_sent = max(paper_vec1.shape[1], paper_vec.shape[1])\n",
    "max_review_sent = max(review_vec1.shape[1], review_vec.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec = np.pad(paper_vec, [(0,0),(0, max_paper_sent-paper_vec.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "review_vec1 = np.pad(review_vec1, [(0,0),(0, max_review_sent-review_vec1.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentic_vec1 = np.pad(sentic_vec1, [(0,0),(0, max_review_sent-sentic_vec1.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_v = np.concatenate((paper_vec, paper_vec1), axis=0)\n",
    "review_v = np.concatenate((review_vec, review_vec1), axis=0)\n",
    "sentic_v = np.concatenate((sentic_vec, sentic_vec1), axis=0)\n",
    "dcsn_v = np.concatenate((dcsn_vec, dcsn_vec1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentic_v = np.pad(sentic_v, [(0,0),(0, 525-sentic_v.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "review_v = np.pad(review_v, [(0,0),(0, 525-review_v.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_v, review_v, sentic_v, dcsn_v):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concatenate 2017 and 2018 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers_train = np.load('./serial/iclr2017/train/papers.npy')\n",
    "# reviews_train = np.load('./serial/iclr2017/train/reviews.npy')\n",
    "# sentiment_train = np.load('./serial/iclr2017/train/sentic.npy')\n",
    "# decision_train = np.load('./serial/iclr2017/train/dcsn.npy')\n",
    "\n",
    "# papers_valid = np.load('./serial/iclr2017/dev/papers.npy')\n",
    "# reviews_valid = np.load('./serial/iclr2017/dev/reviews.npy')\n",
    "# sentiment_valid = np.load('./serial/iclr2017/dev/sentic.npy')\n",
    "# decision_valid = np.load('./serial/iclr2017/dev/dcsn.npy')\n",
    "\n",
    "\n",
    "papers_test = np.load('./serial/iclr2017/test/papers.npy')\n",
    "reviews_test = np.load('./serial/iclr2017/test/reviews.npy')\n",
    "sentiment_test = np.load('./serial/iclr2017/test/sentic.npy')\n",
    "decision_test = np.load('./serial/iclr2017/test/dcsn.npy')\n",
    "\n",
    "\n",
    "# paper_v = np.load('./serial/iclr2018/papers.npy')\n",
    "# review_v = np.load('./serial/iclr2018/reviews.npy')\n",
    "# sentic_v = np.load('./serial/iclr2018/sentic.npy')\n",
    "# dcsn_v = np.load('./serial/iclr2018/dcsn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 1494, 512)\n",
      "(38, 525, 512)\n",
      "(38, 525, 4)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "for i in (papers_test,reviews_test,sentiment_test,decision_test):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in zip((papers_train, reviews_train, sentiment_train, decision_train), (paper_v, review_v, sentic_v, dcsn_v)):\n",
    "    train_data.append(np.concatenate((i[0], i[1]), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 1494, 512)\n",
      "(1258, 525, 512)\n",
      "(1258, 525, 4)\n",
      "(1258,)\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_p, train_r, train_s, train_d = shuffle(train_data[0], train_data[1], train_data[2], train_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 1494, 512)\n",
      "(1258, 525, 512)\n",
      "(1258, 525, 4)\n",
      "(1258,)\n"
     ]
    }
   ],
   "source": [
    "for i in (train_p, train_r, train_s, train_d):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACL_2017 Cross-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import predict1\n",
    "data_padded_, label_scale_, aspects_ = predict1.prepare_data('../../data/iclr_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_padded_[0]:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in data_padded_[0][1]:\n",
    "    print paper.__dict__['ACCEPTED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "none = np.where(np.array(x[5]) == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcsn = np.array(x[5])\n",
    "dcsn[none] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcsn = dcsn.tolist()\n",
    "dcsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,rt,st,dt = get_data((x[0],x[4],dcsn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (pt,rt,st,dt):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.pad(pt, [(0,0),(0, 1494-1373), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "rt = np.pad(rt, [(0,0),(0, 525-156), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "st = np.pad(st, [(0,0),(0, 525-156), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "tt = (pt,rt,st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "torch.cuda.set_device(7)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify(nn.Module):\n",
    "    def __init__(self, rh1, ch1):\n",
    "        super(classify, self).__init__()\n",
    "        \n",
    "        num_classes = 2\n",
    "        \n",
    "#         self.p3 = nn.Sequential(\n",
    "#                             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 5),\n",
    "#                             nn.ReLU()\n",
    "#                             )\n",
    "        self.r3 = nn.Sequential(\n",
    "                            nn.Conv1d(in_channels = 512, out_channels = 64, kernel_size = 5),\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "    \n",
    "        self.s1 = nn.Linear(4*525,rh1)\n",
    "\n",
    "        self.l1 = nn.Linear(64, ch1)\n",
    "        \n",
    "        self.l3 = nn.Linear(2*100,100)\n",
    "        self.l4 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.7)\n",
    "        \n",
    "    def forward(self, paper, review, sentiment):  \n",
    "        batch_size = paper.shape[0]\n",
    "#         out_p3 = self.p3(paper)\n",
    "#         out_p3 = F.max_pool1d(out_p3, out_p3.shape[2])\n",
    "\n",
    "        out_r3 = self.r3(review)\n",
    "        out_r3 = F.max_pool1d(out_r3, out_r3.shape[2])    #out_p/r shape = (batch_size, #filters, 1)\n",
    "        \n",
    "#         out = torch.cat((out_p3, out_r3), dim = 1)         #out shape = (batch_size, num_filters*kernels, 1)\n",
    "        out = out_r3\n",
    "        \n",
    "        r = self.s1(sentiment.view(batch_size, -1))\n",
    "        r = self.dropout(r)\n",
    "        \n",
    "        out = self.l1(out.view(batch_size, -1))\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.l3(torch.cat((out, r), dim = 1))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l4(out)\n",
    "    \n",
    "        \n",
    "        return out,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = classify(100,100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters()) #,weight_decay = 0.0, momentum = 0.9, lr = 0.009)\n",
    "#loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dset(Dataset):\n",
    "    def __init__(self, data, y_data):\n",
    "        x1, x2, x3 = data\n",
    "        assert x1.shape[0] == x2.shape[0]\n",
    "        assert x1.shape[0] == x3.shape[0]\n",
    "        self.len = x1.shape[0]\n",
    "        self.x1_data = x1\n",
    "        self.x2_data = x2\n",
    "        self.x3_data = x3\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x1_data[index,:,:], self.x2_data[index,:,:], self.x3_data[index,:,:]), self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Dset, batch_size, num_workers):\n",
    "    loader = DataLoader(Dset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(preds, true):\n",
    "#     preds = preds.detach().cpu().numpy()\n",
    "#     true = true.detach().cpu().numpy()\n",
    "#     labels = np.argmax(preds, axis = 1)\n",
    "#     return np.sum(np.array(labels == true).astype(int))/float(true.shape[0]), zip(labels, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = dset((train_p, train_r, train_s), train_d)\n",
    "trainloader = load_data(trainD, batch_size = 32, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validD = dset((papers_valid, reviews_valid, sentiment_valid), decision_valid)\n",
    "validloader = load_data(validD, batch_size = 32, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, params):\n",
    "    model.train()\n",
    "    steps = 0\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    best_val_acc = 0.0\n",
    "    log_after_interval = params['log_after_interval']\n",
    "    eval_after_interval = params['eval_after_interval']\n",
    "    epochs = params['epochs']\n",
    "    writer = SummaryWriter(comment = 'Decision(r+s),' + str(params['lr']) + ' ' + str(params['l2']))\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = []\n",
    "        training_acc = []\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            (papers, reviews, sentiment), decision = data\n",
    "            papers = papers.transpose(1,2).float().to(device)\n",
    "            reviews = reviews.transpose(1,2).float().to(device)\n",
    "            sentiment = sentiment.transpose(1,2).float().to(device)\n",
    "            decision = decision.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(papers, reviews, sentiment)\n",
    "            \n",
    "            pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "            acc = (pred.item()/decision.size()[0])\n",
    "            \n",
    "            los = F.cross_entropy(out, decision)\n",
    "            training_loss.append(los.item())\n",
    "            training_acc.append(acc)\n",
    "            loss_log.append(los.item())\n",
    "            acc_log.append(acc)\n",
    "            \n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps%log_after_interval == 0:\n",
    "#                 pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "#                 acc = (pred.item()/decision.size()[0])\n",
    "                print('Epoch[{}/{}] Iteration[{}]-loss: {:.6f} acc: {:.4f}'.format(epoch, epochs, steps, np.average(loss_log), np.average(acc_log)))\n",
    "                loss_log = []\n",
    "                acc_log = []\n",
    "            if steps%eval_after_interval == 0:\n",
    "                dl, da = evaluate(validloader, model)\n",
    "                if best_val_acc < da:\n",
    "                    best_val_acc = da\n",
    "                    print('Saving model with validation accuracy: {}'.format(da))\n",
    "                    checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                }\n",
    "                    with open('./trained_task2/rs/' + params['iteration'] + '.model', 'wb') as f:\n",
    "                        torch.save(checkpoint, f)\n",
    "                    with open('./trained_task2/rs/' + params['iteration'] + '.json', 'w') as f:\n",
    "                        json.dump(params, f)\n",
    "            steps+=1\n",
    "        writer.add_scalar('training_loss', np.average(training_loss), epoch)\n",
    "        writer.add_scalar('training_acc', np.average(training_acc), epoch)\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(validloader, model):\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    model.eval()\n",
    "    for i, data in enumerate(validloader,0):\n",
    "        (papers, reviews, sentiment), decision = data\n",
    "        papers = papers.transpose(1,2).float().to(device)\n",
    "        reviews = reviews.transpose(1,2).float().to(device)\n",
    "        sentiment = sentiment.transpose(1,2).float().to(device)\n",
    "        decision = decision.to(device)\n",
    "        \n",
    "        out,r = model(papers, reviews, sentiment)\n",
    "        los = F.cross_entropy(out, decision)\n",
    "        val_loss.append(los.item())\n",
    "        pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "        acc = (pred.item()/decision.size()[0])\n",
    "        val_acc.append(acc)\n",
    "    print('Evaluation- loss: {:.6f} acc: {:.4f}'.format(np.average(val_loss), np.average(val_acc)))#, pred,decision.size()[0]))\n",
    "    return np.average(val_loss), np.average(val_acc), out,decision,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gridtest():\n",
    "\n",
    "    lrate = [0.5,0.1, 0.07, 0.05, 0.03, 0.01, 0.007, 0.005, 0.003,0.001, 0.0007, 0.0005, 0.0003, 0.0001, 0.00005]\n",
    "    decay = [0.0001, 0.005, 0.001, 0.05, 0.01, 0.5, 0.1, 0.0, 1.0, 2.0 ]\n",
    "\n",
    "    for l in lrate:\n",
    "        for d in decay:\n",
    "            print('testing with lr {} and l2 {}'.format(l, d))\n",
    "            params = {\n",
    "                         'optimizer': 'SGD',\n",
    "                         'Type': 'Review+Sentiment',\n",
    "                         'Filter_size': '64 on review',\n",
    "                         'Dropout': 0.7,\n",
    "                        'lr':l,\n",
    "                        'l2': d,\n",
    "                        'batch-size': 32,\n",
    "                         'iteration': str(int(time.time())),\n",
    "                        'epochs': 50,\n",
    "                        'log_after_interval': 20,\n",
    "                        'eval_after_interval': 20\n",
    "            }\n",
    "            model = classify(100,100).to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(),weight_decay = d, momentum = 0.9, lr = l)\n",
    "            train(model, optimizer, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with lr 0.5 and l2 0.0001\n",
      "Epoch[0/50] Iteration[0]-loss: 0.723728 acc: 0.3750\n",
      "Evaluation- loss: 0.666226 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[0/50] Iteration[20]-loss: 2.984619 acc: 0.5734\n",
      "Evaluation- loss: 82.558015 acc: 0.5000\n",
      "Epoch[1/50] Iteration[40]-loss: 2.149756 acc: 0.5653\n",
      "Evaluation- loss: 0.685930 acc: 0.5625\n",
      "Epoch[1/50] Iteration[60]-loss: 0.701431 acc: 0.5656\n",
      "Evaluation- loss: 0.717858 acc: 0.5781\n",
      "Epoch[2/50] Iteration[80]-loss: 0.665036 acc: 0.6316\n",
      "Evaluation- loss: 0.692192 acc: 0.5312\n",
      "Epoch[2/50] Iteration[100]-loss: 0.665034 acc: 0.6328\n",
      "Evaluation- loss: 0.681961 acc: 0.5781\n",
      "Epoch[3/50] Iteration[120]-loss: 0.721882 acc: 0.5509\n",
      "Evaluation- loss: 0.846221 acc: 0.5312\n",
      "Epoch[3/50] Iteration[140]-loss: 0.724020 acc: 0.5594\n",
      "Evaluation- loss: 0.693633 acc: 0.4688\n",
      "Epoch[4/50] Iteration[160]-loss: 0.704493 acc: 0.5800\n",
      "Evaluation- loss: 0.740491 acc: 0.5781\n",
      "Epoch[4/50] Iteration[180]-loss: 0.701717 acc: 0.5422\n",
      "Evaluation- loss: 0.690145 acc: 0.5781\n",
      "Epoch[5/50] Iteration[200]-loss: 0.688272 acc: 0.6397\n",
      "Evaluation- loss: 0.703513 acc: 0.4688\n",
      "Epoch[5/50] Iteration[220]-loss: 0.697053 acc: 0.5375\n",
      "Evaluation- loss: 0.676484 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[6/50] Iteration[240]-loss: 0.663203 acc: 0.6428\n",
      "Evaluation- loss: 0.782593 acc: 0.5312\n",
      "Epoch[6/50] Iteration[260]-loss: 0.670502 acc: 0.6203\n",
      "Evaluation- loss: 0.720930 acc: 0.5312\n",
      "Epoch[7/50] Iteration[280]-loss: 0.676551 acc: 0.5881\n",
      "Evaluation- loss: 0.698531 acc: 0.6250\n",
      "Epoch[7/50] Iteration[300]-loss: 0.688711 acc: 0.5813\n",
      "Evaluation- loss: 0.686595 acc: 0.5781\n",
      "Epoch[8/50] Iteration[320]-loss: 0.658294 acc: 0.6506\n",
      "Evaluation- loss: 0.748021 acc: 0.5781\n",
      "Epoch[8/50] Iteration[340]-loss: 0.660407 acc: 0.6500\n",
      "Evaluation- loss: 0.696138 acc: 0.5312\n",
      "Epoch[9/50] Iteration[360]-loss: 0.698304 acc: 0.5206\n",
      "Evaluation- loss: 0.741007 acc: 0.5312\n",
      "Epoch[9/50] Iteration[380]-loss: 0.658898 acc: 0.6391\n",
      "Evaluation- loss: 0.673520 acc: 0.6250\n",
      "Epoch[10/50] Iteration[400]-loss: 0.684796 acc: 0.5872\n",
      "Evaluation- loss: 0.729263 acc: 0.4688\n",
      "Epoch[10/50] Iteration[420]-loss: 0.706725 acc: 0.5406\n",
      "Evaluation- loss: 0.679202 acc: 0.6719\n",
      "Epoch[11/50] Iteration[440]-loss: 0.714619 acc: 0.5594\n",
      "Evaluation- loss: 0.741675 acc: 0.4688\n",
      "Epoch[11/50] Iteration[460]-loss: 0.686812 acc: 0.5922\n",
      "Evaluation- loss: 0.692567 acc: 0.5312\n",
      "Epoch[12/50] Iteration[480]-loss: 0.667917 acc: 0.6244\n",
      "Evaluation- loss: 0.691708 acc: 0.5312\n",
      "Epoch[12/50] Iteration[500]-loss: 0.685900 acc: 0.5703\n",
      "Evaluation- loss: 0.781318 acc: 0.5312\n",
      "Epoch[13/50] Iteration[520]-loss: 0.683735 acc: 0.6191\n",
      "Evaluation- loss: 0.698959 acc: 0.4375\n",
      "Epoch[13/50] Iteration[540]-loss: 0.682803 acc: 0.6125\n",
      "Evaluation- loss: 0.661960 acc: 0.6250\n",
      "Epoch[14/50] Iteration[560]-loss: 0.669886 acc: 0.6209\n",
      "Evaluation- loss: 0.716196 acc: 0.5312\n",
      "Epoch[14/50] Iteration[580]-loss: 0.674164 acc: 0.6234\n",
      "Evaluation- loss: 0.692840 acc: 0.5312\n",
      "Epoch[15/50] Iteration[600]-loss: 0.684368 acc: 0.5506\n",
      "Evaluation- loss: 0.681100 acc: 0.5781\n",
      "Epoch[15/50] Iteration[620]-loss: 0.664726 acc: 0.6312\n",
      "Evaluation- loss: 0.726059 acc: 0.5312\n",
      "Epoch[16/50] Iteration[640]-loss: 0.687048 acc: 0.5966\n",
      "Evaluation- loss: 0.681408 acc: 0.5781\n",
      "Epoch[16/50] Iteration[660]-loss: 0.677896 acc: 0.6125\n",
      "Evaluation- loss: 0.649738 acc: 0.6719\n",
      "Epoch[17/50] Iteration[680]-loss: 0.689489 acc: 0.6044\n",
      "Evaluation- loss: 0.691415 acc: 0.5312\n",
      "Epoch[17/50] Iteration[700]-loss: 0.715651 acc: 0.5609\n",
      "Evaluation- loss: 0.696529 acc: 0.3750\n",
      "Epoch[18/50] Iteration[720]-loss: 0.687192 acc: 0.5769\n",
      "Evaluation- loss: 0.696370 acc: 0.6250\n",
      "Epoch[18/50] Iteration[740]-loss: 0.663636 acc: 0.5984\n",
      "Evaluation- loss: 0.802543 acc: 0.4844\n",
      "Epoch[19/50] Iteration[760]-loss: 0.677781 acc: 0.6084\n",
      "Evaluation- loss: 0.699504 acc: 0.5781\n",
      "Epoch[19/50] Iteration[780]-loss: 0.691637 acc: 0.5828\n",
      "Evaluation- loss: 0.683921 acc: 0.5781\n",
      "Epoch[20/50] Iteration[800]-loss: 0.661842 acc: 0.6350\n",
      "Evaluation- loss: 0.826025 acc: 0.5312\n",
      "Epoch[20/50] Iteration[820]-loss: 0.673353 acc: 0.6234\n",
      "Evaluation- loss: 0.661944 acc: 0.6250\n",
      "Epoch[21/50] Iteration[840]-loss: 0.670303 acc: 0.6125\n",
      "Evaluation- loss: 0.685677 acc: 0.5781\n",
      "Epoch[21/50] Iteration[860]-loss: 0.664389 acc: 0.6312\n",
      "Evaluation- loss: 0.685878 acc: 0.6250\n",
      "Epoch[22/50] Iteration[880]-loss: 0.684746 acc: 0.6166\n",
      "Evaluation- loss: 0.681031 acc: 0.5781\n",
      "Epoch[22/50] Iteration[900]-loss: 0.667030 acc: 0.6250\n",
      "Evaluation- loss: 0.674309 acc: 0.6250\n",
      "Epoch[23/50] Iteration[920]-loss: 0.681280 acc: 0.5800\n",
      "Evaluation- loss: 0.729173 acc: 0.5781\n",
      "Epoch[23/50] Iteration[940]-loss: 0.671392 acc: 0.5938\n",
      "Evaluation- loss: 0.681136 acc: 0.5781\n",
      "Epoch[24/50] Iteration[960]-loss: 0.684779 acc: 0.5734\n",
      "Evaluation- loss: 0.765646 acc: 0.4844\n",
      "Epoch[24/50] Iteration[980]-loss: 0.685339 acc: 0.5922\n",
      "Evaluation- loss: 0.691534 acc: 0.5312\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.670560 acc: 0.6506\n",
      "Evaluation- loss: 0.681829 acc: 0.5781\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.677704 acc: 0.6234\n",
      "Evaluation- loss: 0.683895 acc: 0.6250\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.681590 acc: 0.5813\n",
      "Evaluation- loss: 0.680922 acc: 0.5781\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.677056 acc: 0.6078\n",
      "Evaluation- loss: 0.681890 acc: 0.5781\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.674013 acc: 0.6312\n",
      "Evaluation- loss: 0.693088 acc: 0.6250\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.698216 acc: 0.5406\n",
      "Evaluation- loss: 0.721701 acc: 0.3281\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.660838 acc: 0.6444\n",
      "Evaluation- loss: 0.761171 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.698642 acc: 0.5734\n",
      "Evaluation- loss: 0.686705 acc: 0.5781\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.672005 acc: 0.6169\n",
      "Evaluation- loss: 0.906549 acc: 0.5312\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.754565 acc: 0.5687\n",
      "Evaluation- loss: 0.757417 acc: 0.3750\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.736700 acc: 0.5112\n",
      "Evaluation- loss: 0.918119 acc: 0.5781\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.790033 acc: 0.5344\n",
      "Evaluation- loss: 0.749463 acc: 0.4688\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.705654 acc: 0.5472\n",
      "Evaluation- loss: 0.806088 acc: 0.5312\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.658209 acc: 0.6625\n",
      "Evaluation- loss: 0.736306 acc: 0.6250\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.690495 acc: 0.5713\n",
      "Evaluation- loss: 0.686853 acc: 0.5781\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.684191 acc: 0.5672\n",
      "Evaluation- loss: 0.965744 acc: 0.4844\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.726131 acc: 0.5662\n",
      "Evaluation- loss: 0.695834 acc: 0.4688\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.686143 acc: 0.5875\n",
      "Evaluation- loss: 0.667182 acc: 0.6719\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.680279 acc: 0.6022\n",
      "Evaluation- loss: 1.022368 acc: 0.4375\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.690925 acc: 0.6328\n",
      "Evaluation- loss: 0.746253 acc: 0.5312\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.681784 acc: 0.6009\n",
      "Evaluation- loss: 0.706096 acc: 0.4844\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.673366 acc: 0.6312\n",
      "Evaluation- loss: 0.767215 acc: 0.4844\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.674013 acc: 0.5872\n",
      "Evaluation- loss: 0.711788 acc: 0.6250\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.711971 acc: 0.5500\n",
      "Evaluation- loss: 0.686886 acc: 0.5781\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.703529 acc: 0.5613\n",
      "Evaluation- loss: 0.683464 acc: 0.5781\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.695646 acc: 0.5703\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.688676 acc: 0.6034\n",
      "Evaluation- loss: 0.803035 acc: 0.5781\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.722896 acc: 0.5469\n",
      "Evaluation- loss: 0.728839 acc: 0.5312\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.687536 acc: 0.6097\n",
      "Evaluation- loss: 0.744928 acc: 0.5312\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.718840 acc: 0.5406\n",
      "Evaluation- loss: 0.730644 acc: 0.4688\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.702953 acc: 0.5672\n",
      "Evaluation- loss: 0.765097 acc: 0.4844\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.720107 acc: 0.5141\n",
      "Evaluation- loss: 0.695125 acc: 0.6250\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.695832 acc: 0.5894\n",
      "Evaluation- loss: 0.704151 acc: 0.5312\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.671195 acc: 0.6172\n",
      "Evaluation- loss: 0.768093 acc: 0.4375\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.676912 acc: 0.6225\n",
      "Evaluation- loss: 0.706602 acc: 0.5312\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.660991 acc: 0.6438\n",
      "Evaluation- loss: 0.739890 acc: 0.5312\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.674589 acc: 0.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: 0.683673 acc: 0.5781\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.668929 acc: 0.6266\n",
      "Evaluation- loss: 0.778499 acc: 0.4844\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.677673 acc: 0.5850\n",
      "Evaluation- loss: 0.707780 acc: 0.6250\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.687117 acc: 0.5875\n",
      "Evaluation- loss: 0.735103 acc: 0.3281\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.690947 acc: 0.5644\n",
      "Evaluation- loss: 0.814890 acc: 0.4844\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.672864 acc: 0.5906\n",
      "Evaluation- loss: 0.662622 acc: 0.6250\n",
      "testing with lr 0.5 and l2 0.005\n",
      "Epoch[0/50] Iteration[0]-loss: 0.672481 acc: 0.5938\n",
      "Evaluation- loss: 0.659917 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[0/50] Iteration[20]-loss: 0.680095 acc: 0.5953\n",
      "Evaluation- loss: 0.709779 acc: 0.4844\n",
      "Epoch[1/50] Iteration[40]-loss: 0.690240 acc: 0.5859\n",
      "Evaluation- loss: 0.691348 acc: 0.5312\n",
      "Epoch[1/50] Iteration[60]-loss: 0.663976 acc: 0.6156\n",
      "Evaluation- loss: 0.717693 acc: 0.4219\n",
      "Epoch[2/50] Iteration[80]-loss: 0.694892 acc: 0.5613\n",
      "Evaluation- loss: 0.667455 acc: 0.6250\n",
      "Epoch[2/50] Iteration[100]-loss: 0.663822 acc: 0.6297\n",
      "Evaluation- loss: 0.718231 acc: 0.3906\n",
      "Epoch[3/50] Iteration[120]-loss: 0.674525 acc: 0.6128\n",
      "Evaluation- loss: 0.756848 acc: 0.5312\n",
      "Epoch[3/50] Iteration[140]-loss: 0.661472 acc: 0.6516\n",
      "Evaluation- loss: 0.750980 acc: 0.5781\n",
      "Epoch[4/50] Iteration[160]-loss: 0.697381 acc: 0.5278\n",
      "Evaluation- loss: 0.681902 acc: 0.6250\n",
      "Epoch[4/50] Iteration[180]-loss: 0.691872 acc: 0.5672\n",
      "Evaluation- loss: 0.694558 acc: 0.5312\n",
      "Epoch[5/50] Iteration[200]-loss: 0.686317 acc: 0.5819\n",
      "Evaluation- loss: 0.936859 acc: 0.4844\n",
      "Epoch[5/50] Iteration[220]-loss: 0.679463 acc: 0.5969\n",
      "Evaluation- loss: 0.681921 acc: 0.5781\n",
      "Epoch[6/50] Iteration[240]-loss: 0.690444 acc: 0.5925\n",
      "Evaluation- loss: 0.682381 acc: 0.5781\n",
      "Epoch[6/50] Iteration[260]-loss: 0.666138 acc: 0.6562\n",
      "Evaluation- loss: 0.666206 acc: 0.6250\n",
      "Epoch[7/50] Iteration[280]-loss: 0.700364 acc: 0.5481\n",
      "Evaluation- loss: 0.695599 acc: 0.4688\n",
      "Epoch[7/50] Iteration[300]-loss: 0.680041 acc: 0.6188\n",
      "Evaluation- loss: 0.743419 acc: 0.5312\n",
      "Epoch[8/50] Iteration[320]-loss: 0.677465 acc: 0.6084\n",
      "Evaluation- loss: 0.720324 acc: 0.4844\n",
      "Epoch[8/50] Iteration[340]-loss: 0.670470 acc: 0.6172\n",
      "Evaluation- loss: 0.681538 acc: 0.5781\n",
      "Epoch[9/50] Iteration[360]-loss: 0.682825 acc: 0.6225\n",
      "Evaluation- loss: 0.833351 acc: 0.5312\n",
      "Epoch[9/50] Iteration[380]-loss: 0.688670 acc: 0.5844\n",
      "Evaluation- loss: 0.736219 acc: 0.5312\n",
      "Epoch[10/50] Iteration[400]-loss: 0.674697 acc: 0.5931\n",
      "Evaluation- loss: 0.691646 acc: 0.5781\n",
      "Epoch[10/50] Iteration[420]-loss: 0.696636 acc: 0.5578\n",
      "Evaluation- loss: 0.876868 acc: 0.4844\n",
      "Epoch[11/50] Iteration[440]-loss: 0.674872 acc: 0.6297\n",
      "Evaluation- loss: 0.682491 acc: 0.5781\n",
      "Epoch[11/50] Iteration[460]-loss: 0.695432 acc: 0.5719\n",
      "Evaluation- loss: 0.716374 acc: 0.4844\n",
      "Epoch[12/50] Iteration[480]-loss: 0.675279 acc: 0.5859\n",
      "Evaluation- loss: 0.677234 acc: 0.6250\n",
      "Epoch[12/50] Iteration[500]-loss: 0.668341 acc: 0.5984\n",
      "Evaluation- loss: 0.661712 acc: 0.6250\n",
      "Epoch[13/50] Iteration[520]-loss: 0.673963 acc: 0.5912\n",
      "Evaluation- loss: 0.807177 acc: 0.4375\n",
      "Epoch[13/50] Iteration[540]-loss: 0.674125 acc: 0.6359\n",
      "Evaluation- loss: 0.697899 acc: 0.5312\n",
      "Epoch[14/50] Iteration[560]-loss: 0.673724 acc: 0.6081\n",
      "Evaluation- loss: 0.923335 acc: 0.3906\n",
      "Epoch[14/50] Iteration[580]-loss: 0.693687 acc: 0.5672\n",
      "Evaluation- loss: 0.707330 acc: 0.4688\n",
      "Epoch[15/50] Iteration[600]-loss: 0.705982 acc: 0.5381\n",
      "Evaluation- loss: 0.827286 acc: 0.5312\n",
      "Epoch[15/50] Iteration[620]-loss: 0.697696 acc: 0.5375\n",
      "Evaluation- loss: 0.672343 acc: 0.6250\n",
      "Epoch[16/50] Iteration[640]-loss: 0.652851 acc: 0.6138\n",
      "Evaluation- loss: 0.854029 acc: 0.5781\n",
      "Epoch[16/50] Iteration[660]-loss: 0.721851 acc: 0.5531\n",
      "Evaluation- loss: 0.723923 acc: 0.4688\n",
      "Epoch[17/50] Iteration[680]-loss: 0.711020 acc: 0.5328\n",
      "Evaluation- loss: 0.682328 acc: 0.5781\n",
      "Epoch[17/50] Iteration[700]-loss: 0.684175 acc: 0.5984\n",
      "Evaluation- loss: 0.746239 acc: 0.4844\n",
      "Epoch[18/50] Iteration[720]-loss: 0.688528 acc: 0.5988\n",
      "Evaluation- loss: 0.758698 acc: 0.4219\n",
      "Epoch[18/50] Iteration[740]-loss: 0.681670 acc: 0.5687\n",
      "Evaluation- loss: 0.885288 acc: 0.4844\n",
      "Epoch[19/50] Iteration[760]-loss: 0.682118 acc: 0.6225\n",
      "Evaluation- loss: 0.729712 acc: 0.4844\n",
      "Epoch[19/50] Iteration[780]-loss: 0.693998 acc: 0.5609\n",
      "Evaluation- loss: 0.682135 acc: 0.5781\n",
      "Epoch[20/50] Iteration[800]-loss: 0.673801 acc: 0.6366\n",
      "Evaluation- loss: 0.713681 acc: 0.4375\n",
      "Epoch[20/50] Iteration[820]-loss: 0.675148 acc: 0.6312\n",
      "Evaluation- loss: 0.701654 acc: 0.5312\n",
      "Epoch[21/50] Iteration[840]-loss: 0.676815 acc: 0.6325\n",
      "Evaluation- loss: 0.721018 acc: 0.5781\n",
      "Epoch[21/50] Iteration[860]-loss: 0.716120 acc: 0.5656\n",
      "Evaluation- loss: 0.693639 acc: 0.4844\n",
      "Epoch[22/50] Iteration[880]-loss: 0.667619 acc: 0.6250\n",
      "Evaluation- loss: 0.695872 acc: 0.5312\n",
      "Epoch[22/50] Iteration[900]-loss: 0.676113 acc: 0.6234\n",
      "Evaluation- loss: 0.770414 acc: 0.5781\n",
      "Epoch[23/50] Iteration[920]-loss: 0.693708 acc: 0.5725\n",
      "Evaluation- loss: 0.686293 acc: 0.6250\n",
      "Epoch[23/50] Iteration[940]-loss: 0.679356 acc: 0.6125\n",
      "Evaluation- loss: 0.687179 acc: 0.5781\n",
      "Epoch[24/50] Iteration[960]-loss: 0.671048 acc: 0.6287\n",
      "Evaluation- loss: 0.714923 acc: 0.5312\n",
      "Epoch[24/50] Iteration[980]-loss: 0.711402 acc: 0.5359\n",
      "Evaluation- loss: 0.733835 acc: 0.5312\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.661749 acc: 0.6175\n",
      "Evaluation- loss: 0.671590 acc: 0.6250\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.679800 acc: 0.5906\n",
      "Evaluation- loss: 0.714465 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.689153 acc: 0.5938\n",
      "Evaluation- loss: 0.707552 acc: 0.5312\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.665444 acc: 0.6266\n",
      "Evaluation- loss: 0.677074 acc: 0.6250\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.674465 acc: 0.6178\n",
      "Evaluation- loss: 0.753623 acc: 0.4844\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.655135 acc: 0.6531\n",
      "Evaluation- loss: 0.802790 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.719843 acc: 0.5075\n",
      "Evaluation- loss: 0.691389 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.727122 acc: 0.5844\n",
      "Evaluation- loss: 0.749145 acc: 0.4844\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.707407 acc: 0.5256\n",
      "Evaluation- loss: 0.757292 acc: 0.5312\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.701764 acc: 0.5547\n",
      "Evaluation- loss: 0.693566 acc: 0.5156\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.673393 acc: 0.5972\n",
      "Evaluation- loss: 0.691657 acc: 0.5312\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.753239 acc: 0.4984\n",
      "Evaluation- loss: 0.915703 acc: 0.5312\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.697546 acc: 0.5563\n",
      "Evaluation- loss: 0.708365 acc: 0.3281\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.676368 acc: 0.5734\n",
      "Evaluation- loss: 0.730866 acc: 0.5312\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.708575 acc: 0.5706\n",
      "Evaluation- loss: 0.703362 acc: 0.4688\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.698761 acc: 0.5594\n",
      "Evaluation- loss: 0.744131 acc: 0.4844\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.686821 acc: 0.5841\n",
      "Evaluation- loss: 0.670018 acc: 0.6250\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.675098 acc: 0.6219\n",
      "Evaluation- loss: 0.680981 acc: 0.5781\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.684437 acc: 0.5775\n",
      "Evaluation- loss: 0.682194 acc: 0.5781\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.671136 acc: 0.6297\n",
      "Evaluation- loss: 0.715362 acc: 0.5312\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.664083 acc: 0.6241\n",
      "Evaluation- loss: 0.736313 acc: 0.5312\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.672176 acc: 0.6188\n",
      "Evaluation- loss: 0.739165 acc: 0.5312\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.665616 acc: 0.6256\n",
      "Evaluation- loss: 0.681098 acc: 0.5781\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.667209 acc: 0.6406\n",
      "Evaluation- loss: 0.696945 acc: 0.5312\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.725344 acc: 0.5200\n",
      "Evaluation- loss: 0.706174 acc: 0.5312\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.662507 acc: 0.6375\n",
      "Evaluation- loss: 0.746666 acc: 0.5312\n",
      "Epoch[38/50] Iteration[1520]-loss: 0.679456 acc: 0.5844\n",
      "Evaluation- loss: 0.683265 acc: 0.5781\n",
      "Epoch[38/50] Iteration[1540]-loss: 0.686649 acc: 0.5828\n",
      "Evaluation- loss: 0.668181 acc: 0.6250\n",
      "Epoch[39/50] Iteration[1560]-loss: 0.664385 acc: 0.6206\n",
      "Evaluation- loss: 0.633582 acc: 0.6719\n",
      "Epoch[39/50] Iteration[1580]-loss: 0.665216 acc: 0.6359\n",
      "Evaluation- loss: 0.703982 acc: 0.5312\n",
      "Epoch[40/50] Iteration[1600]-loss: 0.691351 acc: 0.5631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: 0.685088 acc: 0.5781\n",
      "Epoch[40/50] Iteration[1620]-loss: 0.685213 acc: 0.5797\n",
      "Evaluation- loss: 0.681170 acc: 0.5781\n",
      "Epoch[41/50] Iteration[1640]-loss: 0.659030 acc: 0.6491\n",
      "Evaluation- loss: 0.711599 acc: 0.6250\n",
      "Epoch[41/50] Iteration[1660]-loss: 0.656099 acc: 0.6219\n",
      "Evaluation- loss: 0.729530 acc: 0.5312\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.680106 acc: 0.5766\n",
      "Evaluation- loss: 0.719703 acc: 0.4375\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.687363 acc: 0.6109\n",
      "Evaluation- loss: 0.692789 acc: 0.5156\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.712600 acc: 0.5247\n",
      "Evaluation- loss: 0.692402 acc: 0.5781\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.744149 acc: 0.5219\n",
      "Evaluation- loss: 1.029900 acc: 0.4375\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.687521 acc: 0.5866\n",
      "Evaluation- loss: 0.700516 acc: 0.4844\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.676064 acc: 0.6250\n",
      "Evaluation- loss: 0.696764 acc: 0.5312\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.677447 acc: 0.6031\n",
      "Evaluation- loss: 0.714966 acc: 0.5781\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.684160 acc: 0.5734\n",
      "Evaluation- loss: 0.736015 acc: 0.5312\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.660921 acc: 0.6441\n",
      "Evaluation- loss: 0.681961 acc: 0.5781\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.679246 acc: 0.5859\n",
      "Evaluation- loss: 0.692953 acc: 0.5781\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.664030 acc: 0.6084\n",
      "Evaluation- loss: 0.786265 acc: 0.5312\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.686213 acc: 0.5828\n",
      "Evaluation- loss: 0.701013 acc: 0.4844\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.674253 acc: 0.6016\n",
      "Evaluation- loss: 0.704641 acc: 0.4688\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.678977 acc: 0.5906\n",
      "Evaluation- loss: 0.713525 acc: 0.5312\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.691114 acc: 0.6000\n",
      "Evaluation- loss: 0.682934 acc: 0.5781\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.680876 acc: 0.5641\n",
      "Evaluation- loss: 0.602827 acc: 0.7188\n",
      "Saving model with validation accuracy: 0.71875\n",
      "testing with lr 0.5 and l2 0.001\n",
      "Epoch[0/50] Iteration[0]-loss: 0.697319 acc: 0.4688\n",
      "Evaluation- loss: 0.689749 acc: 0.5156\n",
      "Saving model with validation accuracy: 0.515625\n",
      "Epoch[0/50] Iteration[20]-loss: 1.075001 acc: 0.5453\n",
      "Evaluation- loss: 84.861156 acc: 0.4688\n",
      "Epoch[1/50] Iteration[40]-loss: 6.146347 acc: 0.5437\n",
      "Evaluation- loss: 0.850469 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[1/50] Iteration[60]-loss: 0.790436 acc: 0.4750\n",
      "Evaluation- loss: 0.835762 acc: 0.5312\n",
      "Epoch[2/50] Iteration[80]-loss: 0.699453 acc: 0.5822\n",
      "Evaluation- loss: 0.691891 acc: 0.5781\n",
      "Epoch[2/50] Iteration[100]-loss: 0.675783 acc: 0.6250\n",
      "Evaluation- loss: 0.771841 acc: 0.5312\n",
      "Epoch[3/50] Iteration[120]-loss: 0.726593 acc: 0.5747\n",
      "Evaluation- loss: 0.754044 acc: 0.4688\n",
      "Epoch[3/50] Iteration[140]-loss: 0.692775 acc: 0.6188\n",
      "Evaluation- loss: 0.669115 acc: 0.6250\n",
      "Epoch[4/50] Iteration[160]-loss: 0.680656 acc: 0.5722\n",
      "Evaluation- loss: 0.691884 acc: 0.5312\n",
      "Epoch[4/50] Iteration[180]-loss: 0.680817 acc: 0.6000\n",
      "Evaluation- loss: 0.715776 acc: 0.5312\n",
      "Epoch[5/50] Iteration[200]-loss: 0.665041 acc: 0.6428\n",
      "Evaluation- loss: 0.907541 acc: 0.4375\n",
      "Epoch[5/50] Iteration[220]-loss: 0.692723 acc: 0.5625\n",
      "Evaluation- loss: 0.712636 acc: 0.5312\n",
      "Epoch[6/50] Iteration[240]-loss: 0.673492 acc: 0.6406\n",
      "Evaluation- loss: 0.691474 acc: 0.5312\n",
      "Epoch[6/50] Iteration[260]-loss: 0.678518 acc: 0.6234\n",
      "Evaluation- loss: 0.709180 acc: 0.5312\n",
      "Epoch[7/50] Iteration[280]-loss: 0.714569 acc: 0.5159\n",
      "Evaluation- loss: 0.752948 acc: 0.5781\n",
      "Epoch[7/50] Iteration[300]-loss: 0.675989 acc: 0.6188\n",
      "Evaluation- loss: 0.682151 acc: 0.6094\n",
      "Epoch[8/50] Iteration[320]-loss: 0.725125 acc: 0.5784\n",
      "Evaluation- loss: 1.048771 acc: 0.4375\n",
      "Epoch[8/50] Iteration[340]-loss: 0.693776 acc: 0.5813\n",
      "Evaluation- loss: 0.689475 acc: 0.5781\n",
      "Epoch[9/50] Iteration[360]-loss: 0.696509 acc: 0.5547\n",
      "Evaluation- loss: 0.770136 acc: 0.4844\n",
      "Epoch[9/50] Iteration[380]-loss: 0.670039 acc: 0.6141\n",
      "Evaluation- loss: 0.635642 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[10/50] Iteration[400]-loss: 0.717000 acc: 0.5447\n",
      "Evaluation- loss: 0.709720 acc: 0.5312\n",
      "Epoch[10/50] Iteration[420]-loss: 0.709090 acc: 0.5594\n",
      "Evaluation- loss: 0.691315 acc: 0.5312\n",
      "Epoch[11/50] Iteration[440]-loss: 0.681144 acc: 0.6375\n",
      "Evaluation- loss: 0.737895 acc: 0.5781\n",
      "Epoch[11/50] Iteration[460]-loss: 0.725871 acc: 0.5188\n",
      "Evaluation- loss: 0.879597 acc: 0.5312\n",
      "Epoch[12/50] Iteration[480]-loss: 0.711004 acc: 0.5741\n",
      "Evaluation- loss: 0.710369 acc: 0.5312\n",
      "Epoch[12/50] Iteration[500]-loss: 0.679917 acc: 0.6125\n",
      "Evaluation- loss: 0.693732 acc: 0.4219\n",
      "Epoch[13/50] Iteration[520]-loss: 0.673809 acc: 0.6297\n",
      "Evaluation- loss: 0.734402 acc: 0.5781\n",
      "Epoch[13/50] Iteration[540]-loss: 0.694952 acc: 0.5406\n",
      "Evaluation- loss: 0.694433 acc: 0.4688\n",
      "Epoch[14/50] Iteration[560]-loss: 0.673795 acc: 0.5938\n",
      "Evaluation- loss: 0.678442 acc: 0.6250\n",
      "Epoch[14/50] Iteration[580]-loss: 0.691394 acc: 0.5609\n",
      "Evaluation- loss: 0.740109 acc: 0.5781\n",
      "Epoch[15/50] Iteration[600]-loss: 0.671511 acc: 0.6075\n",
      "Evaluation- loss: 0.696470 acc: 0.4844\n",
      "Epoch[15/50] Iteration[620]-loss: 0.675413 acc: 0.6031\n",
      "Evaluation- loss: 0.736601 acc: 0.5312\n",
      "Epoch[16/50] Iteration[640]-loss: 0.669607 acc: 0.6222\n",
      "Evaluation- loss: 0.673445 acc: 0.6250\n",
      "Epoch[16/50] Iteration[660]-loss: 0.674784 acc: 0.6266\n",
      "Evaluation- loss: 0.688611 acc: 0.6250\n",
      "Epoch[17/50] Iteration[680]-loss: 0.702596 acc: 0.5791\n",
      "Evaluation- loss: 0.691538 acc: 0.5312\n",
      "Epoch[17/50] Iteration[700]-loss: 0.692133 acc: 0.5719\n",
      "Evaluation- loss: 0.663366 acc: 0.6250\n",
      "Epoch[18/50] Iteration[720]-loss: 0.670962 acc: 0.6281\n",
      "Evaluation- loss: 0.682262 acc: 0.5781\n",
      "Epoch[18/50] Iteration[740]-loss: 0.666219 acc: 0.6234\n",
      "Evaluation- loss: 0.661618 acc: 0.6250\n",
      "Epoch[19/50] Iteration[760]-loss: 0.685486 acc: 0.5925\n",
      "Evaluation- loss: 0.699134 acc: 0.4688\n",
      "Epoch[19/50] Iteration[780]-loss: 0.707895 acc: 0.5328\n",
      "Evaluation- loss: 0.706112 acc: 0.5312\n",
      "Epoch[20/50] Iteration[800]-loss: 0.662457 acc: 0.6194\n",
      "Evaluation- loss: 0.755361 acc: 0.5312\n",
      "Epoch[20/50] Iteration[820]-loss: 0.720740 acc: 0.5703\n",
      "Evaluation- loss: 0.688374 acc: 0.5781\n",
      "Epoch[21/50] Iteration[840]-loss: 0.742172 acc: 0.5194\n",
      "Evaluation- loss: 0.860509 acc: 0.5781\n",
      "Epoch[21/50] Iteration[860]-loss: 0.737637 acc: 0.5797\n",
      "Evaluation- loss: 0.682079 acc: 0.5781\n",
      "Epoch[22/50] Iteration[880]-loss: 0.725979 acc: 0.5141\n",
      "Evaluation- loss: 0.923838 acc: 0.4375\n",
      "Epoch[22/50] Iteration[900]-loss: 0.724015 acc: 0.5500\n",
      "Evaluation- loss: 0.722774 acc: 0.4688\n",
      "Epoch[23/50] Iteration[920]-loss: 0.666687 acc: 0.6194\n",
      "Evaluation- loss: 0.861926 acc: 0.3906\n",
      "Epoch[23/50] Iteration[940]-loss: 0.675542 acc: 0.6156\n",
      "Evaluation- loss: 0.691260 acc: 0.5312\n",
      "Epoch[24/50] Iteration[960]-loss: 0.685633 acc: 0.6238\n",
      "Evaluation- loss: 0.691254 acc: 0.5312\n",
      "Epoch[24/50] Iteration[980]-loss: 0.726024 acc: 0.5312\n",
      "Evaluation- loss: 0.783567 acc: 0.4844\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.669625 acc: 0.6338\n",
      "Evaluation- loss: 0.668934 acc: 0.6250\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.667343 acc: 0.6250\n",
      "Evaluation- loss: 0.723504 acc: 0.4219\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.698328 acc: 0.5737\n",
      "Evaluation- loss: 0.697048 acc: 0.5781\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.683400 acc: 0.5844\n",
      "Evaluation- loss: 0.722033 acc: 0.5312\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.675982 acc: 0.6056\n",
      "Evaluation- loss: 0.929615 acc: 0.4844\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.705076 acc: 0.5594\n",
      "Evaluation- loss: 0.714073 acc: 0.4219\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.709747 acc: 0.5684\n",
      "Evaluation- loss: 0.667153 acc: 0.6250\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.739489 acc: 0.5203\n",
      "Evaluation- loss: 0.821966 acc: 0.5312\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.700358 acc: 0.6028\n",
      "Evaluation- loss: 0.690446 acc: 0.5781\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.686803 acc: 0.6219\n",
      "Evaluation- loss: 0.698513 acc: 0.4844\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.681155 acc: 0.5694\n",
      "Evaluation- loss: 0.716526 acc: 0.5781\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.695698 acc: 0.5891\n",
      "Evaluation- loss: 0.741992 acc: 0.4375\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.695116 acc: 0.5319\n",
      "Evaluation- loss: 0.743227 acc: 0.5781\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.678331 acc: 0.6016\n",
      "Evaluation- loss: 0.723815 acc: 0.2812\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.667502 acc: 0.6144\n",
      "Evaluation- loss: 0.779340 acc: 0.4375\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.692210 acc: 0.6141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: 0.712420 acc: 0.4844\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.681522 acc: 0.5634\n",
      "Evaluation- loss: 0.668351 acc: 0.6250\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.678912 acc: 0.5844\n",
      "Evaluation- loss: 0.694563 acc: 0.5312\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.677116 acc: 0.6381\n",
      "Evaluation- loss: 0.932530 acc: 0.3906\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.701330 acc: 0.5172\n",
      "Evaluation- loss: 0.693374 acc: 0.4844\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.685372 acc: 0.6200\n",
      "Evaluation- loss: 0.686590 acc: 0.5781\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.684336 acc: 0.5672\n",
      "Evaluation- loss: 0.683278 acc: 0.6250\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.667451 acc: 0.6394\n",
      "Evaluation- loss: 0.680945 acc: 0.5781\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.678101 acc: 0.5813\n",
      "Evaluation- loss: 0.681223 acc: 0.5781\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.679745 acc: 0.6169\n",
      "Evaluation- loss: 0.687598 acc: 0.5625\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.672152 acc: 0.6109\n",
      "Evaluation- loss: 0.720922 acc: 0.5781\n",
      "Epoch[38/50] Iteration[1520]-loss: 0.689052 acc: 0.5772\n",
      "Evaluation- loss: 0.666988 acc: 0.6250\n",
      "Epoch[38/50] Iteration[1540]-loss: 0.686496 acc: 0.5609\n",
      "Evaluation- loss: 0.696127 acc: 0.6250\n",
      "Epoch[39/50] Iteration[1560]-loss: 0.668739 acc: 0.6100\n",
      "Evaluation- loss: 0.708213 acc: 0.5312\n",
      "Epoch[39/50] Iteration[1580]-loss: 0.699376 acc: 0.5625\n",
      "Evaluation- loss: 0.673456 acc: 0.6250\n",
      "Epoch[40/50] Iteration[1600]-loss: 0.673322 acc: 0.6231\n",
      "Evaluation- loss: 0.661889 acc: 0.6250\n",
      "Epoch[40/50] Iteration[1620]-loss: 0.672253 acc: 0.6125\n",
      "Evaluation- loss: 0.669523 acc: 0.6250\n",
      "Epoch[41/50] Iteration[1640]-loss: 0.667004 acc: 0.6225\n",
      "Evaluation- loss: 0.680557 acc: 0.6250\n",
      "Epoch[41/50] Iteration[1660]-loss: 0.694479 acc: 0.5734\n",
      "Evaluation- loss: 0.654376 acc: 0.6719\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.674603 acc: 0.6338\n",
      "Evaluation- loss: 0.761702 acc: 0.5312\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.665930 acc: 0.6062\n",
      "Evaluation- loss: 0.694436 acc: 0.5312\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.688092 acc: 0.5691\n",
      "Evaluation- loss: 0.667217 acc: 0.6250\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.665265 acc: 0.6375\n",
      "Evaluation- loss: 0.862789 acc: 0.4844\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.686378 acc: 0.5734\n",
      "Evaluation- loss: 0.695205 acc: 0.5312\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.676976 acc: 0.5875\n",
      "Evaluation- loss: 0.681308 acc: 0.5781\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.669681 acc: 0.6238\n",
      "Evaluation- loss: 0.662629 acc: 0.6250\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.697227 acc: 0.5719\n",
      "Evaluation- loss: 0.697041 acc: 0.5781\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.669744 acc: 0.6281\n",
      "Evaluation- loss: 0.735149 acc: 0.4375\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.693136 acc: 0.5422\n",
      "Evaluation- loss: 0.691752 acc: 0.5312\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.701915 acc: 0.6022\n",
      "Evaluation- loss: 0.743147 acc: 0.5781\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.671365 acc: 0.5875\n",
      "Evaluation- loss: 0.756530 acc: 0.4844\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.664595 acc: 0.6266\n",
      "Evaluation- loss: 0.704870 acc: 0.4844\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.673873 acc: 0.5922\n",
      "Evaluation- loss: 0.736496 acc: 0.5312\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.659187 acc: 0.6397\n",
      "Evaluation- loss: 0.685713 acc: 0.5781\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.695806 acc: 0.5844\n",
      "Evaluation- loss: 0.661930 acc: 0.6250\n",
      "testing with lr 0.5 and l2 0.05\n",
      "Epoch[0/50] Iteration[0]-loss: 0.660236 acc: 0.7188\n",
      "Evaluation- loss: 0.658766 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[0/50] Iteration[20]-loss: 0.713543 acc: 0.6000\n",
      "Evaluation- loss: 2.230497 acc: 0.5625\n",
      "Epoch[1/50] Iteration[40]-loss: nan acc: 0.5681\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[1/50] Iteration[60]-loss: nan acc: 0.5969\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[2/50] Iteration[80]-loss: nan acc: 0.6519\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[2/50] Iteration[100]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[3/50] Iteration[120]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[3/50] Iteration[140]-loss: nan acc: 0.5984\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[4/50] Iteration[160]-loss: nan acc: 0.6475\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[4/50] Iteration[180]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[5/50] Iteration[200]-loss: nan acc: 0.6394\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[5/50] Iteration[220]-loss: nan acc: 0.6203\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[6/50] Iteration[240]-loss: nan acc: 0.6078\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[6/50] Iteration[260]-loss: nan acc: 0.6344\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[7/50] Iteration[280]-loss: nan acc: 0.6172\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[7/50] Iteration[300]-loss: nan acc: 0.6109\n",
      "Evaluation- loss: nan acc: 0.3906\n",
      "Epoch[8/50] Iteration[320]-loss: nan acc: 0.6269\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[8/50] Iteration[340]-loss: nan acc: 0.6359\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[9/50] Iteration[360]-loss: nan acc: 0.6116\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[9/50] Iteration[380]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[10/50] Iteration[400]-loss: nan acc: 0.6300\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[10/50] Iteration[420]-loss: nan acc: 0.6109\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[11/50] Iteration[440]-loss: nan acc: 0.6406\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[11/50] Iteration[460]-loss: nan acc: 0.6078\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[12/50] Iteration[480]-loss: nan acc: 0.6381\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[12/50] Iteration[500]-loss: nan acc: 0.6281\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[13/50] Iteration[520]-loss: nan acc: 0.6175\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[13/50] Iteration[540]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[14/50] Iteration[560]-loss: nan acc: 0.6222\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[14/50] Iteration[580]-loss: nan acc: 0.6344\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[15/50] Iteration[600]-loss: nan acc: 0.6231\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[15/50] Iteration[620]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[16/50] Iteration[640]-loss: nan acc: 0.6381\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[16/50] Iteration[660]-loss: nan acc: 0.6312\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[17/50] Iteration[680]-loss: nan acc: 0.6038\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[17/50] Iteration[700]-loss: nan acc: 0.6359\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[18/50] Iteration[720]-loss: nan acc: 0.6128\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[18/50] Iteration[740]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[19/50] Iteration[760]-loss: nan acc: 0.6334\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[19/50] Iteration[780]-loss: nan acc: 0.6281\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[20/50] Iteration[800]-loss: nan acc: 0.6041\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[20/50] Iteration[820]-loss: nan acc: 0.6453\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[21/50] Iteration[840]-loss: nan acc: 0.5922\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[21/50] Iteration[860]-loss: nan acc: 0.6141\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[22/50] Iteration[880]-loss: nan acc: 0.6334\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[22/50] Iteration[900]-loss: nan acc: 0.6250\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[23/50] Iteration[920]-loss: nan acc: 0.6006\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[23/50] Iteration[940]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[24/50] Iteration[960]-loss: nan acc: 0.6200\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[24/50] Iteration[980]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[25/50] Iteration[1000]-loss: nan acc: 0.6191\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[25/50] Iteration[1020]-loss: nan acc: 0.6109\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[26/50] Iteration[1040]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[26/50] Iteration[1060]-loss: nan acc: 0.6406\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[27/50] Iteration[1080]-loss: nan acc: 0.6016\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[27/50] Iteration[1100]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[28/50] Iteration[1120]-loss: nan acc: 0.6338\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[28/50] Iteration[1140]-loss: nan acc: 0.6031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[29/50] Iteration[1160]-loss: nan acc: 0.6438\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[29/50] Iteration[1180]-loss: nan acc: 0.6141\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[30/50] Iteration[1200]-loss: nan acc: 0.6219\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[30/50] Iteration[1220]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[31/50] Iteration[1240]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[31/50] Iteration[1260]-loss: nan acc: 0.6250\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[32/50] Iteration[1280]-loss: nan acc: 0.6175\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[32/50] Iteration[1300]-loss: nan acc: 0.6078\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[33/50] Iteration[1320]-loss: nan acc: 0.6375\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[33/50] Iteration[1340]-loss: nan acc: 0.6016\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[34/50] Iteration[1360]-loss: nan acc: 0.6391\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[34/50] Iteration[1380]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[35/50] Iteration[1400]-loss: nan acc: 0.6197\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[35/50] Iteration[1420]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[36/50] Iteration[1440]-loss: nan acc: 0.6366\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[36/50] Iteration[1460]-loss: nan acc: 0.6172\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[37/50] Iteration[1480]-loss: nan acc: 0.6306\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[37/50] Iteration[1500]-loss: nan acc: 0.6172\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[38/50] Iteration[1520]-loss: nan acc: 0.6369\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[38/50] Iteration[1540]-loss: nan acc: 0.5953\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[39/50] Iteration[1560]-loss: nan acc: 0.6428\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[39/50] Iteration[1580]-loss: nan acc: 0.6391\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[40/50] Iteration[1600]-loss: nan acc: 0.6025\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[40/50] Iteration[1620]-loss: nan acc: 0.6125\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[41/50] Iteration[1640]-loss: nan acc: 0.6269\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[41/50] Iteration[1660]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[42/50] Iteration[1680]-loss: nan acc: 0.6322\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[42/50] Iteration[1700]-loss: nan acc: 0.6047\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[43/50] Iteration[1720]-loss: nan acc: 0.6328\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[43/50] Iteration[1740]-loss: nan acc: 0.6453\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[44/50] Iteration[1760]-loss: nan acc: 0.6003\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[44/50] Iteration[1780]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[45/50] Iteration[1800]-loss: nan acc: 0.6216\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[45/50] Iteration[1820]-loss: nan acc: 0.6203\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[46/50] Iteration[1840]-loss: nan acc: 0.6131\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[46/50] Iteration[1860]-loss: nan acc: 0.6547\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[47/50] Iteration[1880]-loss: nan acc: 0.6016\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[47/50] Iteration[1900]-loss: nan acc: 0.6297\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[48/50] Iteration[1920]-loss: nan acc: 0.6112\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[48/50] Iteration[1940]-loss: nan acc: 0.6250\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[49/50] Iteration[1960]-loss: nan acc: 0.6244\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[49/50] Iteration[1980]-loss: nan acc: 0.6375\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "testing with lr 0.5 and l2 0.01\n",
      "Epoch[0/50] Iteration[0]-loss: 0.672865 acc: 0.6250\n",
      "Evaluation- loss: 0.717349 acc: 0.5312\n",
      "Saving model with validation accuracy: 0.53125\n",
      "Epoch[0/50] Iteration[20]-loss: 0.854815 acc: 0.5484\n",
      "Evaluation- loss: 1.173308 acc: 0.5781\n",
      "Saving model with validation accuracy: 0.578125\n",
      "Epoch[1/50] Iteration[40]-loss: 1.032335 acc: 0.5503\n",
      "Evaluation- loss: 7.107731 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[1/50] Iteration[60]-loss: nan acc: 0.5328\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[2/50] Iteration[80]-loss: nan acc: 0.6394\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[2/50] Iteration[100]-loss: nan acc: 0.6344\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[3/50] Iteration[120]-loss: nan acc: 0.6181\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[3/50] Iteration[140]-loss: nan acc: 0.6344\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[4/50] Iteration[160]-loss: nan acc: 0.5997\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[4/50] Iteration[180]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[5/50] Iteration[200]-loss: nan acc: 0.6362\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[5/50] Iteration[220]-loss: nan acc: 0.6375\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[6/50] Iteration[240]-loss: nan acc: 0.6016\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[6/50] Iteration[260]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[7/50] Iteration[280]-loss: nan acc: 0.6241\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[7/50] Iteration[300]-loss: nan acc: 0.6312\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[8/50] Iteration[320]-loss: nan acc: 0.6047\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[8/50] Iteration[340]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[9/50] Iteration[360]-loss: nan acc: 0.6287\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[9/50] Iteration[380]-loss: nan acc: 0.6375\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[10/50] Iteration[400]-loss: nan acc: 0.6106\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[10/50] Iteration[420]-loss: nan acc: 0.6047\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[11/50] Iteration[440]-loss: nan acc: 0.6466\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[11/50] Iteration[460]-loss: nan acc: 0.6328\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[12/50] Iteration[480]-loss: nan acc: 0.6106\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[12/50] Iteration[500]-loss: nan acc: 0.6453\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[13/50] Iteration[520]-loss: nan acc: 0.5869\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[13/50] Iteration[540]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[14/50] Iteration[560]-loss: nan acc: 0.6213\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[14/50] Iteration[580]-loss: nan acc: 0.6031\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[15/50] Iteration[600]-loss: nan acc: 0.6466\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[15/50] Iteration[620]-loss: nan acc: 0.6109\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[16/50] Iteration[640]-loss: nan acc: 0.6122\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[16/50] Iteration[660]-loss: nan acc: 0.6391\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[17/50] Iteration[680]-loss: nan acc: 0.6262\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[17/50] Iteration[700]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[18/50] Iteration[720]-loss: nan acc: 0.6044\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[18/50] Iteration[740]-loss: nan acc: 0.6484\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[19/50] Iteration[760]-loss: nan acc: 0.6006\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[19/50] Iteration[780]-loss: nan acc: 0.6312\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[20/50] Iteration[800]-loss: nan acc: 0.6150\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[20/50] Iteration[820]-loss: nan acc: 0.6422\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[21/50] Iteration[840]-loss: nan acc: 0.6213\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "Epoch[21/50] Iteration[860]-loss: nan acc: 0.6062\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[22/50] Iteration[880]-loss: nan acc: 0.6378\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[22/50] Iteration[900]-loss: nan acc: 0.6406\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[23/50] Iteration[920]-loss: nan acc: 0.5922\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[23/50] Iteration[940]-loss: nan acc: 0.6125\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[24/50] Iteration[960]-loss: nan acc: 0.6462\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[24/50] Iteration[980]-loss: nan acc: 0.6047\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[25/50] Iteration[1000]-loss: nan acc: 0.6447\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[25/50] Iteration[1020]-loss: nan acc: 0.6078\n",
      "Evaluation- loss: nan acc: 0.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/50] Iteration[1040]-loss: nan acc: 0.6269\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[26/50] Iteration[1060]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[27/50] Iteration[1080]-loss: nan acc: 0.6528\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[27/50] Iteration[1100]-loss: nan acc: 0.6250\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[28/50] Iteration[1120]-loss: nan acc: 0.6100\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[28/50] Iteration[1140]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[29/50] Iteration[1160]-loss: nan acc: 0.6172\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[29/50] Iteration[1180]-loss: nan acc: 0.6469\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[30/50] Iteration[1200]-loss: nan acc: 0.5847\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[30/50] Iteration[1220]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[31/50] Iteration[1240]-loss: nan acc: 0.6328\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[31/50] Iteration[1260]-loss: nan acc: 0.6344\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[32/50] Iteration[1280]-loss: nan acc: 0.6100\n",
      "Evaluation- loss: nan acc: 0.4375\n",
      "Epoch[32/50] Iteration[1300]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[33/50] Iteration[1320]-loss: nan acc: 0.6125\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[33/50] Iteration[1340]-loss: nan acc: 0.6391\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[34/50] Iteration[1360]-loss: nan acc: 0.6034\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[34/50] Iteration[1380]-loss: nan acc: 0.6422\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[35/50] Iteration[1400]-loss: nan acc: 0.6000\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[35/50] Iteration[1420]-loss: nan acc: 0.6312\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[36/50] Iteration[1440]-loss: nan acc: 0.6213\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[36/50] Iteration[1460]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[37/50] Iteration[1480]-loss: nan acc: 0.6275\n",
      "Evaluation- loss: nan acc: 0.3906\n",
      "Epoch[37/50] Iteration[1500]-loss: nan acc: 0.6188\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[38/50] Iteration[1520]-loss: nan acc: 0.6206\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[38/50] Iteration[1540]-loss: nan acc: 0.6469\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[39/50] Iteration[1560]-loss: nan acc: 0.6003\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[39/50] Iteration[1580]-loss: nan acc: 0.6234\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[40/50] Iteration[1600]-loss: nan acc: 0.6256\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[40/50] Iteration[1620]-loss: nan acc: 0.6375\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[41/50] Iteration[1640]-loss: nan acc: 0.6034\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[41/50] Iteration[1660]-loss: nan acc: 0.6312\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[42/50] Iteration[1680]-loss: nan acc: 0.6091\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[42/50] Iteration[1700]-loss: nan acc: 0.6156\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[43/50] Iteration[1720]-loss: nan acc: 0.6272\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[43/50] Iteration[1740]-loss: nan acc: 0.6266\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[44/50] Iteration[1760]-loss: nan acc: 0.6162\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[44/50] Iteration[1780]-loss: nan acc: 0.6406\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[45/50] Iteration[1800]-loss: nan acc: 0.6128\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[45/50] Iteration[1820]-loss: nan acc: 0.6281\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[46/50] Iteration[1840]-loss: nan acc: 0.6028\n",
      "Evaluation- loss: nan acc: 0.4844\n",
      "Epoch[46/50] Iteration[1860]-loss: nan acc: 0.6203\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[47/50] Iteration[1880]-loss: nan acc: 0.6416\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[47/50] Iteration[1900]-loss: nan acc: 0.6094\n",
      "Evaluation- loss: nan acc: 0.6250\n",
      "Epoch[48/50] Iteration[1920]-loss: nan acc: 0.6353\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[48/50] Iteration[1940]-loss: nan acc: 0.6203\n",
      "Evaluation- loss: nan acc: 0.5781\n",
      "Epoch[49/50] Iteration[1960]-loss: nan acc: 0.6175\n",
      "Evaluation- loss: nan acc: 0.5312\n",
      "Epoch[49/50] Iteration[1980]-loss: nan acc: 0.6328\n",
      "Evaluation- loss: nan acc: 0.6719\n",
      "testing with lr 0.5 and l2 0.5\n",
      "Epoch[0/50] Iteration[0]-loss: 0.695907 acc: 0.4688\n",
      "Evaluation- loss: 0.680959 acc: 0.5781\n",
      "Saving model with validation accuracy: 0.578125\n",
      "Epoch[0/50] Iteration[20]-loss: 0.673281 acc: 0.6141\n",
      "Evaluation- loss: 0.682461 acc: 0.5781\n",
      "Epoch[1/50] Iteration[40]-loss: 0.673268 acc: 0.5722\n",
      "Evaluation- loss: 0.717496 acc: 0.5312\n",
      "Epoch[1/50] Iteration[60]-loss: 0.677787 acc: 0.5625\n",
      "Evaluation- loss: 0.785928 acc: 0.4375\n",
      "Epoch[2/50] Iteration[80]-loss: 0.684732 acc: 0.5672\n",
      "Evaluation- loss: 0.684416 acc: 0.5781\n",
      "Epoch[2/50] Iteration[100]-loss: 0.671023 acc: 0.5859\n",
      "Evaluation- loss: 0.681718 acc: 0.5781\n",
      "Epoch[3/50] Iteration[120]-loss: 0.674729 acc: 0.5831\n",
      "Evaluation- loss: 0.682325 acc: 0.5781\n",
      "Epoch[3/50] Iteration[140]-loss: 0.679176 acc: 0.5781\n",
      "Evaluation- loss: 0.702232 acc: 0.4844\n",
      "Epoch[4/50] Iteration[160]-loss: 0.675253 acc: 0.5978\n",
      "Evaluation- loss: 0.750934 acc: 0.4844\n",
      "Epoch[4/50] Iteration[180]-loss: 0.690425 acc: 0.5328\n",
      "Evaluation- loss: 0.690708 acc: 0.5781\n",
      "Epoch[5/50] Iteration[200]-loss: 0.675153 acc: 0.6003\n",
      "Evaluation- loss: 0.695524 acc: 0.4844\n",
      "Epoch[5/50] Iteration[220]-loss: 0.683879 acc: 0.5625\n",
      "Evaluation- loss: 0.741986 acc: 0.4844\n",
      "Epoch[6/50] Iteration[240]-loss: 0.668058 acc: 0.6325\n",
      "Evaluation- loss: 0.700437 acc: 0.3750\n",
      "Epoch[6/50] Iteration[260]-loss: 0.680417 acc: 0.5687\n",
      "Evaluation- loss: 0.691273 acc: 0.5312\n",
      "Epoch[7/50] Iteration[280]-loss: 0.675936 acc: 0.5784\n",
      "Evaluation- loss: 0.669748 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[7/50] Iteration[300]-loss: 0.678631 acc: 0.5781\n",
      "Evaluation- loss: 0.661837 acc: 0.6250\n",
      "Epoch[8/50] Iteration[320]-loss: 0.697299 acc: 0.5097\n",
      "Evaluation- loss: 0.683772 acc: 0.5781\n",
      "Epoch[8/50] Iteration[340]-loss: 0.669746 acc: 0.5656\n",
      "Evaluation- loss: 0.825520 acc: 0.4844\n",
      "Epoch[9/50] Iteration[360]-loss: 0.683804 acc: 0.5737\n",
      "Evaluation- loss: 0.682469 acc: 0.5781\n",
      "Epoch[9/50] Iteration[380]-loss: 0.689570 acc: 0.5984\n",
      "Evaluation- loss: 0.724279 acc: 0.4844\n",
      "Epoch[10/50] Iteration[400]-loss: 0.683600 acc: 0.5575\n",
      "Evaluation- loss: 0.712872 acc: 0.4688\n",
      "Epoch[10/50] Iteration[420]-loss: 0.695390 acc: 0.5031\n",
      "Evaluation- loss: 0.667407 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[11/50] Iteration[440]-loss: 0.688500 acc: 0.5453\n",
      "Evaluation- loss: 0.748855 acc: 0.4844\n",
      "Epoch[11/50] Iteration[460]-loss: 0.700279 acc: 0.5344\n",
      "Evaluation- loss: 0.685888 acc: 0.5625\n",
      "Epoch[12/50] Iteration[480]-loss: 0.684859 acc: 0.5513\n",
      "Evaluation- loss: 0.695101 acc: 0.4688\n",
      "Epoch[12/50] Iteration[500]-loss: 0.666018 acc: 0.6125\n",
      "Evaluation- loss: 0.668700 acc: 0.6250\n",
      "Epoch[13/50] Iteration[520]-loss: 0.679951 acc: 0.5912\n",
      "Evaluation- loss: 0.692927 acc: 0.5312\n",
      "Epoch[13/50] Iteration[540]-loss: 0.688416 acc: 0.5609\n",
      "Evaluation- loss: 0.668554 acc: 0.6250\n",
      "Epoch[14/50] Iteration[560]-loss: 0.675060 acc: 0.6038\n",
      "Evaluation- loss: 0.701048 acc: 0.4844\n",
      "Epoch[14/50] Iteration[580]-loss: 0.673988 acc: 0.6062\n",
      "Evaluation- loss: 0.719795 acc: 0.4844\n",
      "Epoch[15/50] Iteration[600]-loss: 0.668651 acc: 0.6156\n",
      "Evaluation- loss: 0.688826 acc: 0.5781\n",
      "Epoch[15/50] Iteration[620]-loss: 0.687107 acc: 0.5188\n",
      "Evaluation- loss: 0.635888 acc: 0.6719\n",
      "Epoch[16/50] Iteration[640]-loss: 0.693103 acc: 0.5363\n",
      "Evaluation- loss: 0.691574 acc: 0.5625\n",
      "Epoch[16/50] Iteration[660]-loss: 0.693164 acc: 0.5312\n",
      "Evaluation- loss: 0.816837 acc: 0.3281\n",
      "Epoch[17/50] Iteration[680]-loss: 0.715927 acc: 0.5106\n",
      "Evaluation- loss: 0.667502 acc: 0.6250\n",
      "Epoch[17/50] Iteration[700]-loss: 0.678492 acc: 0.6078\n",
      "Evaluation- loss: 0.691437 acc: 0.5312\n",
      "Epoch[18/50] Iteration[720]-loss: 0.677794 acc: 0.5634\n",
      "Evaluation- loss: 0.683161 acc: 0.5781\n",
      "Epoch[18/50] Iteration[740]-loss: 0.678282 acc: 0.5594\n",
      "Evaluation- loss: 0.633297 acc: 0.6719\n",
      "Epoch[19/50] Iteration[760]-loss: 0.672887 acc: 0.6213\n",
      "Evaluation- loss: 0.714778 acc: 0.5312\n",
      "Epoch[19/50] Iteration[780]-loss: 0.672204 acc: 0.6031\n",
      "Evaluation- loss: 0.675587 acc: 0.6250\n",
      "Epoch[20/50] Iteration[800]-loss: 0.674168 acc: 0.5769\n",
      "Evaluation- loss: 0.704737 acc: 0.4219\n",
      "Epoch[20/50] Iteration[820]-loss: 0.665398 acc: 0.6125\n",
      "Evaluation- loss: 0.675698 acc: 0.6250\n",
      "Epoch[21/50] Iteration[840]-loss: 0.684782 acc: 0.5456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: 0.687403 acc: 0.5781\n",
      "Epoch[21/50] Iteration[860]-loss: 0.667507 acc: 0.6078\n",
      "Evaluation- loss: 0.692032 acc: 0.5312\n",
      "Epoch[22/50] Iteration[880]-loss: 0.682758 acc: 0.5941\n",
      "Evaluation- loss: 0.691283 acc: 0.5312\n",
      "Epoch[22/50] Iteration[900]-loss: 0.687905 acc: 0.5578\n",
      "Evaluation- loss: 0.708358 acc: 0.3750\n",
      "Epoch[23/50] Iteration[920]-loss: 0.689744 acc: 0.5475\n",
      "Evaluation- loss: 0.699981 acc: 0.5781\n",
      "Epoch[23/50] Iteration[940]-loss: 0.679622 acc: 0.5625\n",
      "Evaluation- loss: 0.741182 acc: 0.5312\n",
      "Epoch[24/50] Iteration[960]-loss: 0.695698 acc: 0.5662\n",
      "Evaluation- loss: 0.697284 acc: 0.4844\n",
      "Epoch[24/50] Iteration[980]-loss: 0.687260 acc: 0.5750\n",
      "Evaluation- loss: 0.795778 acc: 0.4375\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.670243 acc: 0.6034\n",
      "Evaluation- loss: 0.696812 acc: 0.5312\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.676060 acc: 0.5609\n",
      "Evaluation- loss: 0.664047 acc: 0.6250\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.671372 acc: 0.6181\n",
      "Evaluation- loss: 0.700492 acc: 0.5781\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.677886 acc: 0.5953\n",
      "Evaluation- loss: 0.693515 acc: 0.4688\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.682843 acc: 0.5513\n",
      "Evaluation- loss: 0.716441 acc: 0.4219\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.711835 acc: 0.5109\n",
      "Evaluation- loss: 0.764618 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.692983 acc: 0.5572\n",
      "Evaluation- loss: 0.746897 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.707689 acc: 0.4922\n",
      "Evaluation- loss: 0.698491 acc: 0.3750\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.674053 acc: 0.5831\n",
      "Evaluation- loss: 0.682306 acc: 0.5781\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.676096 acc: 0.5641\n",
      "Evaluation- loss: 0.700401 acc: 0.4844\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.674451 acc: 0.5734\n",
      "Evaluation- loss: 0.703039 acc: 0.5312\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.678330 acc: 0.6031\n",
      "Evaluation- loss: 0.685452 acc: 0.5625\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.692592 acc: 0.5053\n",
      "Evaluation- loss: 0.738903 acc: 0.4844\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.687929 acc: 0.5672\n",
      "Evaluation- loss: 0.725728 acc: 0.4844\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.668441 acc: 0.6197\n",
      "Evaluation- loss: 0.682280 acc: 0.5781\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.669631 acc: 0.6094\n",
      "Evaluation- loss: 0.702293 acc: 0.5312\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.679370 acc: 0.5969\n",
      "Evaluation- loss: 0.728332 acc: 0.4219\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.683347 acc: 0.5469\n",
      "Evaluation- loss: 0.704239 acc: 0.5312\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.679419 acc: 0.5641\n",
      "Evaluation- loss: 0.695837 acc: 0.4688\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.684091 acc: 0.5234\n",
      "Evaluation- loss: 0.694375 acc: 0.5312\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.676787 acc: 0.6319\n",
      "Evaluation- loss: 0.681291 acc: 0.5781\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.661816 acc: 0.6516\n",
      "Evaluation- loss: 0.706065 acc: 0.5312\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.703869 acc: 0.5291\n",
      "Evaluation- loss: 0.757452 acc: 0.3750\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.694780 acc: 0.5297\n",
      "Evaluation- loss: 0.703487 acc: 0.4688\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.676459 acc: 0.5797\n",
      "Evaluation- loss: 0.673746 acc: 0.6719\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.674817 acc: 0.6000\n",
      "Evaluation- loss: 0.609256 acc: 0.7188\n",
      "Saving model with validation accuracy: 0.71875\n",
      "Epoch[38/50] Iteration[1520]-loss: 0.694550 acc: 0.5613\n",
      "Evaluation- loss: 0.698615 acc: 0.4688\n",
      "Epoch[38/50] Iteration[1540]-loss: 0.682740 acc: 0.5719\n",
      "Evaluation- loss: 0.692173 acc: 0.5312\n",
      "Epoch[39/50] Iteration[1560]-loss: 0.657154 acc: 0.6347\n",
      "Evaluation- loss: 0.659768 acc: 0.6719\n",
      "Epoch[39/50] Iteration[1580]-loss: 0.679860 acc: 0.5703\n",
      "Evaluation- loss: 0.698265 acc: 0.5312\n",
      "Epoch[40/50] Iteration[1600]-loss: 0.682851 acc: 0.5900\n",
      "Evaluation- loss: 0.690338 acc: 0.5781\n",
      "Epoch[40/50] Iteration[1620]-loss: 0.671807 acc: 0.5969\n",
      "Evaluation- loss: 0.661913 acc: 0.6250\n",
      "Epoch[41/50] Iteration[1640]-loss: 0.679485 acc: 0.5678\n",
      "Evaluation- loss: 0.681246 acc: 0.5781\n",
      "Epoch[41/50] Iteration[1660]-loss: 0.671402 acc: 0.5766\n",
      "Evaluation- loss: 0.681284 acc: 0.5781\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.679942 acc: 0.5716\n",
      "Evaluation- loss: 0.693764 acc: 0.4375\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.676349 acc: 0.6234\n",
      "Evaluation- loss: 0.745359 acc: 0.4844\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.689018 acc: 0.5425\n",
      "Evaluation- loss: 0.813557 acc: 0.3281\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.701344 acc: 0.5219\n",
      "Evaluation- loss: 0.692247 acc: 0.5781\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.691191 acc: 0.5662\n",
      "Evaluation- loss: 0.847863 acc: 0.4844\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.670075 acc: 0.5938\n",
      "Evaluation- loss: 0.687471 acc: 0.5781\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.684143 acc: 0.5672\n",
      "Evaluation- loss: 0.710027 acc: 0.4219\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.683962 acc: 0.5609\n",
      "Evaluation- loss: 0.681111 acc: 0.5781\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.661898 acc: 0.6494\n",
      "Evaluation- loss: 0.716949 acc: 0.5312\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.675145 acc: 0.5875\n",
      "Evaluation- loss: 0.693684 acc: 0.4688\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.694196 acc: 0.5334\n",
      "Evaluation- loss: 0.736147 acc: 0.4219\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.702765 acc: 0.5312\n",
      "Evaluation- loss: 0.704814 acc: 0.5312\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.670907 acc: 0.5981\n",
      "Evaluation- loss: 0.755900 acc: 0.5312\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.671466 acc: 0.5687\n",
      "Evaluation- loss: 0.684090 acc: 0.5781\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.686734 acc: 0.5391\n",
      "Evaluation- loss: 0.697657 acc: 0.5156\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.678927 acc: 0.5500\n",
      "Evaluation- loss: 0.699583 acc: 0.5312\n",
      "testing with lr 0.5 and l2 0.1\n",
      "Epoch[0/50] Iteration[0]-loss: 0.706833 acc: 0.4375\n",
      "Evaluation- loss: 0.682538 acc: 0.6406\n",
      "Saving model with validation accuracy: 0.640625\n",
      "Epoch[0/50] Iteration[20]-loss: 0.665239 acc: 0.6281\n",
      "Evaluation- loss: 0.736411 acc: 0.4844\n",
      "Epoch[1/50] Iteration[40]-loss: 0.680881 acc: 0.5706\n",
      "Evaluation- loss: 0.692898 acc: 0.5781\n",
      "Epoch[1/50] Iteration[60]-loss: 0.690086 acc: 0.5344\n",
      "Evaluation- loss: 0.680941 acc: 0.5781\n",
      "Epoch[2/50] Iteration[80]-loss: 0.701183 acc: 0.5619\n",
      "Evaluation- loss: 0.693175 acc: 0.4375\n",
      "Epoch[2/50] Iteration[100]-loss: 0.679078 acc: 0.6078\n",
      "Evaluation- loss: 0.698071 acc: 0.4688\n",
      "Epoch[3/50] Iteration[120]-loss: 0.695129 acc: 0.5406\n",
      "Evaluation- loss: 0.763449 acc: 0.4219\n",
      "Epoch[3/50] Iteration[140]-loss: 0.691941 acc: 0.5656\n",
      "Evaluation- loss: 0.649990 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[4/50] Iteration[160]-loss: 0.667668 acc: 0.6181\n",
      "Evaluation- loss: 0.684132 acc: 0.5781\n",
      "Epoch[4/50] Iteration[180]-loss: 0.668568 acc: 0.6312\n",
      "Evaluation- loss: 0.693142 acc: 0.5781\n",
      "Epoch[5/50] Iteration[200]-loss: 0.677284 acc: 0.5816\n",
      "Evaluation- loss: 0.737074 acc: 0.4844\n",
      "Epoch[5/50] Iteration[220]-loss: 0.680422 acc: 0.6125\n",
      "Evaluation- loss: 0.812859 acc: 0.4844\n",
      "Epoch[6/50] Iteration[240]-loss: 0.695169 acc: 0.5516\n",
      "Evaluation- loss: 0.853933 acc: 0.4375\n",
      "Epoch[6/50] Iteration[260]-loss: 0.671874 acc: 0.5969\n",
      "Evaluation- loss: 0.701412 acc: 0.4844\n",
      "Epoch[7/50] Iteration[280]-loss: 0.685666 acc: 0.5706\n",
      "Evaluation- loss: 0.717733 acc: 0.4844\n",
      "Epoch[7/50] Iteration[300]-loss: 0.671370 acc: 0.6141\n",
      "Evaluation- loss: 0.682540 acc: 0.5781\n",
      "Epoch[8/50] Iteration[320]-loss: 0.673627 acc: 0.6203\n",
      "Evaluation- loss: 0.692950 acc: 0.5781\n",
      "Epoch[8/50] Iteration[340]-loss: 0.699746 acc: 0.5500\n",
      "Evaluation- loss: 0.694373 acc: 0.6250\n",
      "Epoch[9/50] Iteration[360]-loss: 0.682218 acc: 0.5456\n",
      "Evaluation- loss: 0.888187 acc: 0.4844\n",
      "Epoch[9/50] Iteration[380]-loss: 0.683778 acc: 0.5938\n",
      "Evaluation- loss: 0.747987 acc: 0.5312\n",
      "Epoch[10/50] Iteration[400]-loss: 0.679246 acc: 0.5753\n",
      "Evaluation- loss: 0.696127 acc: 0.5312\n",
      "Epoch[10/50] Iteration[420]-loss: 0.660146 acc: 0.6234\n",
      "Evaluation- loss: 0.695857 acc: 0.3750\n",
      "Epoch[11/50] Iteration[440]-loss: 0.674431 acc: 0.5819\n",
      "Evaluation- loss: 0.741099 acc: 0.4844\n",
      "Epoch[11/50] Iteration[460]-loss: 0.671471 acc: 0.5984\n",
      "Evaluation- loss: 0.667923 acc: 0.6719\n",
      "Epoch[12/50] Iteration[480]-loss: 0.682368 acc: 0.5988\n",
      "Evaluation- loss: 0.682700 acc: 0.5781\n",
      "Epoch[12/50] Iteration[500]-loss: 0.677735 acc: 0.5953\n",
      "Evaluation- loss: 0.720948 acc: 0.4844\n",
      "Epoch[13/50] Iteration[520]-loss: 0.664063 acc: 0.5866\n",
      "Evaluation- loss: 0.729255 acc: 0.5312\n",
      "Epoch[13/50] Iteration[540]-loss: 0.665299 acc: 0.6406\n",
      "Evaluation- loss: 0.696861 acc: 0.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/50] Iteration[560]-loss: 0.678413 acc: 0.5925\n",
      "Evaluation- loss: 0.766496 acc: 0.4375\n",
      "Epoch[14/50] Iteration[580]-loss: 0.678896 acc: 0.5953\n",
      "Evaluation- loss: 0.683524 acc: 0.5781\n",
      "Epoch[15/50] Iteration[600]-loss: 0.675856 acc: 0.6078\n",
      "Evaluation- loss: 0.681485 acc: 0.5781\n",
      "Epoch[15/50] Iteration[620]-loss: 0.664365 acc: 0.6250\n",
      "Evaluation- loss: 0.691668 acc: 0.5312\n",
      "Epoch[16/50] Iteration[640]-loss: 0.668671 acc: 0.6253\n",
      "Evaluation- loss: 0.721222 acc: 0.4844\n",
      "Epoch[16/50] Iteration[660]-loss: 0.671914 acc: 0.6125\n",
      "Evaluation- loss: 0.704206 acc: 0.5781\n",
      "Epoch[17/50] Iteration[680]-loss: 0.681255 acc: 0.6128\n",
      "Evaluation- loss: 0.712235 acc: 0.4375\n",
      "Epoch[17/50] Iteration[700]-loss: 0.670634 acc: 0.6266\n",
      "Evaluation- loss: 0.652541 acc: 0.6719\n",
      "Epoch[18/50] Iteration[720]-loss: 0.699376 acc: 0.5547\n",
      "Evaluation- loss: 0.715287 acc: 0.5781\n",
      "Epoch[18/50] Iteration[740]-loss: 0.659537 acc: 0.6328\n",
      "Evaluation- loss: 0.669138 acc: 0.6719\n",
      "Epoch[19/50] Iteration[760]-loss: 0.689292 acc: 0.5803\n",
      "Evaluation- loss: 0.692286 acc: 0.5312\n",
      "Epoch[19/50] Iteration[780]-loss: 0.700544 acc: 0.5844\n",
      "Evaluation- loss: 0.727069 acc: 0.5312\n",
      "Epoch[20/50] Iteration[800]-loss: 0.707761 acc: 0.5406\n",
      "Evaluation- loss: 0.768511 acc: 0.5312\n",
      "Epoch[20/50] Iteration[820]-loss: 0.683060 acc: 0.5813\n",
      "Evaluation- loss: 0.673365 acc: 0.6250\n",
      "Epoch[21/50] Iteration[840]-loss: 0.671841 acc: 0.6247\n",
      "Evaluation- loss: 0.692362 acc: 0.5312\n",
      "Epoch[21/50] Iteration[860]-loss: 0.699306 acc: 0.5891\n",
      "Evaluation- loss: 0.692382 acc: 0.5781\n",
      "Epoch[22/50] Iteration[880]-loss: 0.748784 acc: 0.5041\n",
      "Evaluation- loss: 0.765604 acc: 0.4844\n",
      "Epoch[22/50] Iteration[900]-loss: 0.670644 acc: 0.6281\n",
      "Evaluation- loss: 0.704843 acc: 0.5781\n",
      "Epoch[23/50] Iteration[920]-loss: 0.673771 acc: 0.6184\n",
      "Evaluation- loss: 0.710416 acc: 0.4844\n",
      "Epoch[23/50] Iteration[940]-loss: 0.661396 acc: 0.6406\n",
      "Evaluation- loss: 0.713010 acc: 0.5781\n",
      "Epoch[24/50] Iteration[960]-loss: 0.700323 acc: 0.5300\n",
      "Evaluation- loss: 0.667624 acc: 0.6250\n",
      "Epoch[24/50] Iteration[980]-loss: 0.670642 acc: 0.6234\n",
      "Evaluation- loss: 0.696731 acc: 0.4844\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.693395 acc: 0.5819\n",
      "Evaluation- loss: 0.692059 acc: 0.5781\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.691640 acc: 0.5375\n",
      "Evaluation- loss: 0.694097 acc: 0.4844\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.663442 acc: 0.6553\n",
      "Evaluation- loss: 0.664688 acc: 0.6250\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.682838 acc: 0.5906\n",
      "Evaluation- loss: 0.662949 acc: 0.6250\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.664992 acc: 0.6103\n",
      "Evaluation- loss: 0.767682 acc: 0.4219\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.725653 acc: 0.5375\n",
      "Evaluation- loss: 0.694176 acc: 0.4844\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.706909 acc: 0.5709\n",
      "Evaluation- loss: 0.692499 acc: 0.5312\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.676914 acc: 0.5891\n",
      "Evaluation- loss: 0.701653 acc: 0.4844\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.656177 acc: 0.6441\n",
      "Evaluation- loss: 0.717224 acc: 0.4844\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.671758 acc: 0.6188\n",
      "Evaluation- loss: 0.691903 acc: 0.5312\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.685553 acc: 0.5619\n",
      "Evaluation- loss: 0.950584 acc: 0.4375\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.685772 acc: 0.5703\n",
      "Evaluation- loss: 0.683133 acc: 0.5781\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.665591 acc: 0.6331\n",
      "Evaluation- loss: 0.668901 acc: 0.6250\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.674924 acc: 0.6219\n",
      "Evaluation- loss: 0.706486 acc: 0.5312\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.679204 acc: 0.5934\n",
      "Evaluation- loss: 0.696480 acc: 0.5156\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.668757 acc: 0.6109\n",
      "Evaluation- loss: 0.713932 acc: 0.5312\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.698701 acc: 0.5681\n",
      "Evaluation- loss: 0.757294 acc: 0.5312\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.708842 acc: 0.5219\n",
      "Evaluation- loss: 0.859167 acc: 0.5312\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.717964 acc: 0.5391\n",
      "Evaluation- loss: 0.643395 acc: 0.6719\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.663342 acc: 0.6312\n",
      "Evaluation- loss: 0.680722 acc: 0.6250\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.698405 acc: 0.5453\n",
      "Evaluation- loss: 0.713944 acc: 0.3750\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.707739 acc: 0.5578\n",
      "Evaluation- loss: 0.770582 acc: 0.4219\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.732745 acc: 0.5378\n",
      "Evaluation- loss: 0.754202 acc: 0.5312\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.691630 acc: 0.5609\n",
      "Evaluation- loss: 0.748430 acc: 0.5781\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.685666 acc: 0.5731\n",
      "Evaluation- loss: 0.745815 acc: 0.5781\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.687655 acc: 0.5563\n",
      "Evaluation- loss: 0.736498 acc: 0.4688\n",
      "Epoch[38/50] Iteration[1520]-loss: 0.694382 acc: 0.5647\n",
      "Evaluation- loss: 0.750962 acc: 0.4375\n",
      "Epoch[38/50] Iteration[1540]-loss: 0.656753 acc: 0.6422\n",
      "Evaluation- loss: 0.711759 acc: 0.4844\n",
      "Epoch[39/50] Iteration[1560]-loss: 0.681955 acc: 0.5875\n",
      "Evaluation- loss: 0.692943 acc: 0.5156\n",
      "Epoch[39/50] Iteration[1580]-loss: 0.680264 acc: 0.6047\n",
      "Evaluation- loss: 0.661696 acc: 0.6250\n",
      "Epoch[40/50] Iteration[1600]-loss: 0.673790 acc: 0.5853\n",
      "Evaluation- loss: 0.719063 acc: 0.6250\n",
      "Epoch[40/50] Iteration[1620]-loss: 0.689782 acc: 0.5922\n",
      "Evaluation- loss: 0.707334 acc: 0.5781\n",
      "Epoch[41/50] Iteration[1640]-loss: 0.687178 acc: 0.5594\n",
      "Evaluation- loss: 0.681271 acc: 0.5781\n",
      "Epoch[41/50] Iteration[1660]-loss: 0.673301 acc: 0.6219\n",
      "Evaluation- loss: 0.681171 acc: 0.5781\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.670813 acc: 0.6222\n",
      "Evaluation- loss: 0.681438 acc: 0.5781\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.667360 acc: 0.6062\n",
      "Evaluation- loss: 0.684110 acc: 0.5781\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.669025 acc: 0.6156\n",
      "Evaluation- loss: 0.697003 acc: 0.5156\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.706470 acc: 0.5719\n",
      "Evaluation- loss: 0.691859 acc: 0.5312\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.718239 acc: 0.5078\n",
      "Evaluation- loss: 0.701897 acc: 0.6250\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.683345 acc: 0.5703\n",
      "Evaluation- loss: 0.681907 acc: 0.5781\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.673899 acc: 0.6125\n",
      "Evaluation- loss: 0.681325 acc: 0.5781\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.663399 acc: 0.6156\n",
      "Evaluation- loss: 0.702778 acc: 0.3750\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.668521 acc: 0.6138\n",
      "Evaluation- loss: 0.681673 acc: 0.5781\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.661364 acc: 0.6156\n",
      "Evaluation- loss: 0.701987 acc: 0.4844\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.689606 acc: 0.5609\n",
      "Evaluation- loss: 0.686735 acc: 0.5625\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.677811 acc: 0.5859\n",
      "Evaluation- loss: 0.718267 acc: 0.5312\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.668552 acc: 0.6225\n",
      "Evaluation- loss: 0.681746 acc: 0.5781\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.665819 acc: 0.6266\n",
      "Evaluation- loss: 0.699455 acc: 0.5312\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.674865 acc: 0.5791\n",
      "Evaluation- loss: 0.680944 acc: 0.5781\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.666315 acc: 0.6250\n",
      "Evaluation- loss: 0.738166 acc: 0.4219\n",
      "testing with lr 0.5 and l2 0.0\n",
      "Epoch[0/50] Iteration[0]-loss: 0.678629 acc: 0.5938\n",
      "Evaluation- loss: 0.692577 acc: 0.5312\n",
      "Saving model with validation accuracy: 0.53125\n",
      "Epoch[0/50] Iteration[20]-loss: 0.685662 acc: 0.5922\n",
      "Evaluation- loss: 0.723940 acc: 0.4219\n",
      "Epoch[1/50] Iteration[40]-loss: 0.663032 acc: 0.6381\n",
      "Evaluation- loss: 0.747457 acc: 0.4375\n",
      "Epoch[1/50] Iteration[60]-loss: 0.655283 acc: 0.6375\n",
      "Evaluation- loss: 0.726738 acc: 0.4375\n",
      "Epoch[2/50] Iteration[80]-loss: 0.683405 acc: 0.5653\n",
      "Evaluation- loss: 0.877116 acc: 0.5312\n",
      "Epoch[2/50] Iteration[100]-loss: 0.705827 acc: 0.6062\n",
      "Evaluation- loss: 0.692118 acc: 0.5781\n",
      "Saving model with validation accuracy: 0.578125\n",
      "Epoch[3/50] Iteration[120]-loss: 0.670459 acc: 0.5959\n",
      "Evaluation- loss: 0.743240 acc: 0.4844\n",
      "Epoch[3/50] Iteration[140]-loss: 0.674291 acc: 0.6109\n",
      "Evaluation- loss: 0.717930 acc: 0.4844\n",
      "Epoch[4/50] Iteration[160]-loss: 0.661723 acc: 0.6334\n",
      "Evaluation- loss: 0.684681 acc: 0.5781\n",
      "Epoch[4/50] Iteration[180]-loss: 0.682051 acc: 0.6125\n",
      "Evaluation- loss: 0.662322 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[5/50] Iteration[200]-loss: 0.663073 acc: 0.6300\n",
      "Evaluation- loss: 0.691441 acc: 0.5312\n",
      "Epoch[5/50] Iteration[220]-loss: 0.676442 acc: 0.6359\n",
      "Evaluation- loss: 0.750891 acc: 0.4844\n",
      "Epoch[6/50] Iteration[240]-loss: 0.690694 acc: 0.5634\n",
      "Evaluation- loss: 0.771240 acc: 0.5312\n",
      "Epoch[6/50] Iteration[260]-loss: 0.674795 acc: 0.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation- loss: 0.727021 acc: 0.4844\n",
      "Epoch[7/50] Iteration[280]-loss: 0.665706 acc: 0.6256\n",
      "Evaluation- loss: 0.737201 acc: 0.5312\n",
      "Epoch[7/50] Iteration[300]-loss: 0.664706 acc: 0.6312\n",
      "Evaluation- loss: 0.684671 acc: 0.5781\n",
      "Epoch[8/50] Iteration[320]-loss: 0.702677 acc: 0.5316\n",
      "Evaluation- loss: 0.799905 acc: 0.5312\n",
      "Epoch[8/50] Iteration[340]-loss: 0.675617 acc: 0.6219\n",
      "Evaluation- loss: 0.691214 acc: 0.5312\n",
      "Epoch[9/50] Iteration[360]-loss: 0.684262 acc: 0.5878\n",
      "Evaluation- loss: 0.699091 acc: 0.6250\n",
      "Epoch[9/50] Iteration[380]-loss: 0.694340 acc: 0.5563\n",
      "Evaluation- loss: 0.692393 acc: 0.5312\n",
      "Epoch[10/50] Iteration[400]-loss: 0.676040 acc: 0.6081\n",
      "Evaluation- loss: 0.759271 acc: 0.4375\n",
      "Epoch[10/50] Iteration[420]-loss: 0.657049 acc: 0.6406\n",
      "Evaluation- loss: 0.681087 acc: 0.5781\n",
      "Epoch[11/50] Iteration[440]-loss: 0.691912 acc: 0.5494\n",
      "Evaluation- loss: 0.702743 acc: 0.5156\n",
      "Epoch[11/50] Iteration[460]-loss: 0.715679 acc: 0.5625\n",
      "Evaluation- loss: 0.939229 acc: 0.5312\n",
      "Epoch[12/50] Iteration[480]-loss: 0.677969 acc: 0.6116\n",
      "Evaluation- loss: 0.695538 acc: 0.5781\n",
      "Epoch[12/50] Iteration[500]-loss: 0.696354 acc: 0.5906\n",
      "Evaluation- loss: 0.696269 acc: 0.4688\n",
      "Epoch[13/50] Iteration[520]-loss: 0.685781 acc: 0.5909\n",
      "Evaluation- loss: 0.702310 acc: 0.5312\n",
      "Epoch[13/50] Iteration[540]-loss: 0.693012 acc: 0.5797\n",
      "Evaluation- loss: 0.789024 acc: 0.4844\n",
      "Epoch[14/50] Iteration[560]-loss: 0.702789 acc: 0.5484\n",
      "Evaluation- loss: 0.731091 acc: 0.5781\n",
      "Epoch[14/50] Iteration[580]-loss: 0.679658 acc: 0.6078\n",
      "Evaluation- loss: 0.725911 acc: 0.4844\n",
      "Epoch[15/50] Iteration[600]-loss: 0.664919 acc: 0.6300\n",
      "Evaluation- loss: 0.652849 acc: 0.6719\n",
      "Saving model with validation accuracy: 0.671875\n",
      "Epoch[15/50] Iteration[620]-loss: 0.686628 acc: 0.5938\n",
      "Evaluation- loss: 0.681192 acc: 0.5781\n",
      "Epoch[16/50] Iteration[640]-loss: 0.681186 acc: 0.5678\n",
      "Evaluation- loss: 0.756793 acc: 0.4844\n",
      "Epoch[16/50] Iteration[660]-loss: 0.695826 acc: 0.5641\n",
      "Evaluation- loss: 0.691240 acc: 0.5312\n",
      "Epoch[17/50] Iteration[680]-loss: 0.673715 acc: 0.6119\n",
      "Evaluation- loss: 0.771245 acc: 0.5781\n",
      "Epoch[17/50] Iteration[700]-loss: 0.721716 acc: 0.5609\n",
      "Evaluation- loss: 0.681017 acc: 0.5781\n",
      "Epoch[18/50] Iteration[720]-loss: 0.670364 acc: 0.6287\n",
      "Evaluation- loss: 0.706866 acc: 0.5312\n",
      "Epoch[18/50] Iteration[740]-loss: 0.690314 acc: 0.5609\n",
      "Evaluation- loss: 0.692141 acc: 0.5312\n",
      "Epoch[19/50] Iteration[760]-loss: 0.725337 acc: 0.5828\n",
      "Evaluation- loss: 0.731554 acc: 0.5781\n",
      "Epoch[19/50] Iteration[780]-loss: 0.704187 acc: 0.5469\n",
      "Evaluation- loss: 0.717514 acc: 0.4844\n",
      "Epoch[20/50] Iteration[800]-loss: 0.697333 acc: 0.5516\n",
      "Evaluation- loss: 0.703732 acc: 0.5156\n",
      "Epoch[20/50] Iteration[820]-loss: 0.696704 acc: 0.5516\n",
      "Evaluation- loss: 0.730234 acc: 0.5312\n",
      "Epoch[21/50] Iteration[840]-loss: 0.687511 acc: 0.6169\n",
      "Evaluation- loss: 0.693081 acc: 0.5781\n",
      "Epoch[21/50] Iteration[860]-loss: 0.696011 acc: 0.5766\n",
      "Evaluation- loss: 0.777810 acc: 0.5781\n",
      "Epoch[22/50] Iteration[880]-loss: 0.692184 acc: 0.5763\n",
      "Evaluation- loss: 0.664676 acc: 0.6250\n",
      "Epoch[22/50] Iteration[900]-loss: 0.689472 acc: 0.6016\n",
      "Evaluation- loss: 0.725928 acc: 0.5312\n",
      "Epoch[23/50] Iteration[920]-loss: 0.677927 acc: 0.5953\n",
      "Evaluation- loss: 0.681263 acc: 0.5781\n",
      "Epoch[23/50] Iteration[940]-loss: 0.681293 acc: 0.6062\n",
      "Evaluation- loss: 0.722861 acc: 0.5312\n",
      "Epoch[24/50] Iteration[960]-loss: 0.673996 acc: 0.6178\n",
      "Evaluation- loss: 0.710301 acc: 0.5781\n",
      "Epoch[24/50] Iteration[980]-loss: 0.675617 acc: 0.6172\n",
      "Evaluation- loss: 0.690106 acc: 0.6719\n",
      "Epoch[25/50] Iteration[1000]-loss: 0.670901 acc: 0.6319\n",
      "Evaluation- loss: 0.728822 acc: 0.5781\n",
      "Epoch[25/50] Iteration[1020]-loss: 0.661906 acc: 0.6391\n",
      "Evaluation- loss: 0.713547 acc: 0.5312\n",
      "Epoch[26/50] Iteration[1040]-loss: 0.675214 acc: 0.6112\n",
      "Evaluation- loss: 0.706309 acc: 0.4844\n",
      "Epoch[26/50] Iteration[1060]-loss: 0.676585 acc: 0.6297\n",
      "Evaluation- loss: 0.709420 acc: 0.5312\n",
      "Epoch[27/50] Iteration[1080]-loss: 0.717756 acc: 0.5369\n",
      "Evaluation- loss: 0.684398 acc: 0.5781\n",
      "Epoch[27/50] Iteration[1100]-loss: 0.712528 acc: 0.5625\n",
      "Evaluation- loss: 0.705198 acc: 0.4219\n",
      "Epoch[28/50] Iteration[1120]-loss: 0.675823 acc: 0.6003\n",
      "Evaluation- loss: 0.807285 acc: 0.4844\n",
      "Epoch[28/50] Iteration[1140]-loss: 0.688703 acc: 0.6203\n",
      "Evaluation- loss: 0.694102 acc: 0.5312\n",
      "Epoch[29/50] Iteration[1160]-loss: 0.703082 acc: 0.6069\n",
      "Evaluation- loss: 0.662377 acc: 0.6250\n",
      "Epoch[29/50] Iteration[1180]-loss: 0.666749 acc: 0.6453\n",
      "Evaluation- loss: 0.743893 acc: 0.5312\n",
      "Epoch[30/50] Iteration[1200]-loss: 0.699901 acc: 0.5853\n",
      "Evaluation- loss: 0.691795 acc: 0.5781\n",
      "Epoch[30/50] Iteration[1220]-loss: 0.706811 acc: 0.5687\n",
      "Evaluation- loss: 0.685656 acc: 0.5781\n",
      "Epoch[31/50] Iteration[1240]-loss: 0.721959 acc: 0.5391\n",
      "Evaluation- loss: 0.714670 acc: 0.5312\n",
      "Epoch[31/50] Iteration[1260]-loss: 0.681778 acc: 0.6328\n",
      "Evaluation- loss: 0.692647 acc: 0.5312\n",
      "Epoch[32/50] Iteration[1280]-loss: 0.690190 acc: 0.5737\n",
      "Evaluation- loss: 0.693608 acc: 0.5312\n",
      "Epoch[32/50] Iteration[1300]-loss: 0.684039 acc: 0.6078\n",
      "Evaluation- loss: 0.684488 acc: 0.5781\n",
      "Epoch[33/50] Iteration[1320]-loss: 0.675225 acc: 0.6191\n",
      "Evaluation- loss: 0.751364 acc: 0.4375\n",
      "Epoch[33/50] Iteration[1340]-loss: 0.681367 acc: 0.5609\n",
      "Evaluation- loss: 0.719903 acc: 0.4844\n",
      "Epoch[34/50] Iteration[1360]-loss: 0.652085 acc: 0.6278\n",
      "Evaluation- loss: 0.883109 acc: 0.5312\n",
      "Epoch[34/50] Iteration[1380]-loss: 0.714313 acc: 0.5875\n",
      "Evaluation- loss: 0.661594 acc: 0.6250\n",
      "Epoch[35/50] Iteration[1400]-loss: 0.680211 acc: 0.6159\n",
      "Evaluation- loss: 0.661742 acc: 0.6250\n",
      "Epoch[35/50] Iteration[1420]-loss: 0.674921 acc: 0.6047\n",
      "Evaluation- loss: 1.042538 acc: 0.3906\n",
      "Epoch[36/50] Iteration[1440]-loss: 0.688454 acc: 0.5978\n",
      "Evaluation- loss: 0.753783 acc: 0.5312\n",
      "Epoch[36/50] Iteration[1460]-loss: 0.678950 acc: 0.6203\n",
      "Evaluation- loss: 0.711913 acc: 0.5312\n",
      "Epoch[37/50] Iteration[1480]-loss: 0.673113 acc: 0.6162\n",
      "Evaluation- loss: 0.731242 acc: 0.4375\n",
      "Epoch[37/50] Iteration[1500]-loss: 0.673693 acc: 0.5797\n",
      "Evaluation- loss: 0.722179 acc: 0.5781\n",
      "Epoch[38/50] Iteration[1520]-loss: 0.714807 acc: 0.5956\n",
      "Evaluation- loss: 0.692122 acc: 0.5312\n",
      "Epoch[38/50] Iteration[1540]-loss: 0.680983 acc: 0.5828\n",
      "Evaluation- loss: 0.721451 acc: 0.5312\n",
      "Epoch[39/50] Iteration[1560]-loss: 0.665275 acc: 0.6100\n",
      "Evaluation- loss: 0.732891 acc: 0.5781\n",
      "Epoch[39/50] Iteration[1580]-loss: 0.673502 acc: 0.5828\n",
      "Evaluation- loss: 0.755587 acc: 0.4844\n",
      "Epoch[40/50] Iteration[1600]-loss: 0.684576 acc: 0.5988\n",
      "Evaluation- loss: 0.661877 acc: 0.6250\n",
      "Epoch[40/50] Iteration[1620]-loss: 0.705761 acc: 0.5406\n",
      "Evaluation- loss: 0.731383 acc: 0.4688\n",
      "Epoch[41/50] Iteration[1640]-loss: 0.716641 acc: 0.5428\n",
      "Evaluation- loss: 0.705832 acc: 0.5781\n",
      "Epoch[41/50] Iteration[1660]-loss: 0.649833 acc: 0.6469\n",
      "Evaluation- loss: 0.761529 acc: 0.5312\n",
      "Epoch[42/50] Iteration[1680]-loss: 0.681329 acc: 0.5813\n",
      "Evaluation- loss: 0.666199 acc: 0.6250\n",
      "Epoch[42/50] Iteration[1700]-loss: 0.669177 acc: 0.6188\n",
      "Evaluation- loss: 0.748680 acc: 0.4844\n",
      "Epoch[43/50] Iteration[1720]-loss: 0.671517 acc: 0.6156\n",
      "Evaluation- loss: 0.655674 acc: 0.6719\n",
      "Epoch[43/50] Iteration[1740]-loss: 0.680901 acc: 0.5781\n",
      "Evaluation- loss: 0.663879 acc: 0.6250\n",
      "Epoch[44/50] Iteration[1760]-loss: 0.680046 acc: 0.6175\n",
      "Evaluation- loss: 0.845727 acc: 0.4375\n",
      "Epoch[44/50] Iteration[1780]-loss: 0.675711 acc: 0.6266\n",
      "Evaluation- loss: 0.800690 acc: 0.5312\n",
      "Epoch[45/50] Iteration[1800]-loss: 0.673271 acc: 0.6066\n",
      "Evaluation- loss: 0.702249 acc: 0.4219\n",
      "Epoch[45/50] Iteration[1820]-loss: 0.704862 acc: 0.5500\n",
      "Evaluation- loss: 0.697211 acc: 0.5781\n",
      "Epoch[46/50] Iteration[1840]-loss: 0.665014 acc: 0.6419\n",
      "Evaluation- loss: 0.811435 acc: 0.5312\n",
      "Epoch[46/50] Iteration[1860]-loss: 0.689709 acc: 0.5719\n",
      "Evaluation- loss: 0.700629 acc: 0.4688\n",
      "Epoch[47/50] Iteration[1880]-loss: 0.696684 acc: 0.5484\n",
      "Evaluation- loss: 0.731340 acc: 0.5312\n",
      "Epoch[47/50] Iteration[1900]-loss: 0.679634 acc: 0.6172\n",
      "Evaluation- loss: 0.705464 acc: 0.5312\n",
      "Epoch[48/50] Iteration[1920]-loss: 0.691922 acc: 0.5903\n",
      "Evaluation- loss: 0.727489 acc: 0.4844\n",
      "Epoch[48/50] Iteration[1940]-loss: 0.669366 acc: 0.6219\n",
      "Evaluation- loss: 0.730707 acc: 0.4844\n",
      "Epoch[49/50] Iteration[1960]-loss: 0.681450 acc: 0.5834\n",
      "Evaluation- loss: 0.661564 acc: 0.6250\n",
      "Epoch[49/50] Iteration[1980]-loss: 0.688799 acc: 0.6109\n",
      "Evaluation- loss: 0.686317 acc: 0.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with lr 0.5 and l2 1.0\n",
      "Epoch[0/50] Iteration[0]-loss: 0.695357 acc: 0.4062\n",
      "Evaluation- loss: 0.671938 acc: 0.6250\n",
      "Saving model with validation accuracy: 0.625\n",
      "Epoch[0/50] Iteration[20]-loss: 0.681000 acc: 0.5641\n",
      "Evaluation- loss: 0.691243 acc: 0.5312\n",
      "Epoch[1/50] Iteration[40]-loss: 0.680287 acc: 0.5800\n",
      "Evaluation- loss: 0.698596 acc: 0.5312\n",
      "Epoch[1/50] Iteration[60]-loss: 0.713920 acc: 0.4953\n",
      "Evaluation- loss: 0.742786 acc: 0.4844\n",
      "Epoch[2/50] Iteration[80]-loss: 0.675845 acc: 0.5659\n",
      "Evaluation- loss: 0.692778 acc: 0.5156\n",
      "Epoch[2/50] Iteration[100]-loss: 0.677669 acc: 0.5953\n",
      "Evaluation- loss: 0.688204 acc: 0.5781\n",
      "Epoch[3/50] Iteration[120]-loss: 0.679342 acc: 0.5934\n",
      "Evaluation- loss: 0.687139 acc: 0.5781\n",
      "Epoch[3/50] Iteration[140]-loss: 0.677698 acc: 0.5578\n",
      "Evaluation- loss: 0.693669 acc: 0.3750\n",
      "Epoch[4/50] Iteration[160]-loss: 0.682769 acc: 0.5550\n",
      "Evaluation- loss: 0.666407 acc: 0.6250\n",
      "Epoch[4/50] Iteration[180]-loss: 0.679379 acc: 0.5766\n",
      "Evaluation- loss: 0.689868 acc: 0.5781\n",
      "Epoch[5/50] Iteration[200]-loss: 0.684685 acc: 0.5997\n",
      "Evaluation- loss: 0.685469 acc: 0.6250\n",
      "Epoch[5/50] Iteration[220]-loss: 0.682065 acc: 0.5594\n",
      "Evaluation- loss: 0.704519 acc: 0.4688\n",
      "Epoch[6/50] Iteration[240]-loss: 0.698367 acc: 0.5353\n",
      "Evaluation- loss: 0.712462 acc: 0.3750\n",
      "Epoch[6/50] Iteration[260]-loss: 0.678130 acc: 0.5766\n",
      "Evaluation- loss: 0.705774 acc: 0.4844\n",
      "Epoch[7/50] Iteration[280]-loss: 0.676628 acc: 0.5787\n",
      "Evaluation- loss: 0.701908 acc: 0.5312\n",
      "Epoch[7/50] Iteration[300]-loss: 0.668201 acc: 0.5969\n",
      "Evaluation- loss: 0.693152 acc: 0.5156\n",
      "Epoch[8/50] Iteration[320]-loss: 0.688704 acc: 0.5262\n",
      "Evaluation- loss: 0.697154 acc: 0.4688\n",
      "Epoch[8/50] Iteration[340]-loss: 0.686634 acc: 0.5500\n",
      "Evaluation- loss: 0.687962 acc: 0.5781\n",
      "Epoch[9/50] Iteration[360]-loss: 0.677630 acc: 0.5837\n",
      "Evaluation- loss: 0.702812 acc: 0.4844\n",
      "Epoch[9/50] Iteration[380]-loss: 0.686416 acc: 0.5344\n",
      "Evaluation- loss: 0.699349 acc: 0.4844\n",
      "Epoch[10/50] Iteration[400]-loss: 0.679053 acc: 0.5941\n",
      "Evaluation- loss: 0.681031 acc: 0.5781\n",
      "Epoch[10/50] Iteration[420]-loss: 0.685029 acc: 0.5531\n",
      "Evaluation- loss: 0.675718 acc: 0.6250\n",
      "Epoch[11/50] Iteration[440]-loss: 0.668669 acc: 0.5791\n",
      "Evaluation- loss: 0.702364 acc: 0.4688\n",
      "Epoch[11/50] Iteration[460]-loss: 0.682251 acc: 0.5516\n",
      "Evaluation- loss: 0.687764 acc: 0.5781\n",
      "Epoch[12/50] Iteration[480]-loss: 0.675395 acc: 0.5881\n",
      "Evaluation- loss: 0.736143 acc: 0.3750\n",
      "Epoch[12/50] Iteration[500]-loss: 0.681357 acc: 0.5703\n",
      "Evaluation- loss: 0.722711 acc: 0.4844\n",
      "Epoch[13/50] Iteration[520]-loss: 0.680079 acc: 0.5731\n",
      "Evaluation- loss: 0.692499 acc: 0.5312\n",
      "Epoch[13/50] Iteration[540]-loss: 0.689534 acc: 0.5156\n",
      "Evaluation- loss: 0.729402 acc: 0.4844\n",
      "Epoch[14/50] Iteration[560]-loss: 0.689872 acc: 0.5328\n",
      "Evaluation- loss: 0.706164 acc: 0.4375\n",
      "Epoch[14/50] Iteration[580]-loss: 0.682310 acc: 0.5469\n",
      "Evaluation- loss: 0.697385 acc: 0.4688\n",
      "Epoch[15/50] Iteration[600]-loss: 0.682734 acc: 0.5609\n",
      "Evaluation- loss: 0.693010 acc: 0.5156\n",
      "Epoch[15/50] Iteration[620]-loss: 0.683651 acc: 0.5719\n",
      "Evaluation- loss: 0.692668 acc: 0.5312\n",
      "Epoch[16/50] Iteration[640]-loss: 0.678552 acc: 0.5637\n",
      "Evaluation- loss: 0.694482 acc: 0.5156\n",
      "Epoch[16/50] Iteration[660]-loss: 0.686372 acc: 0.5516\n",
      "Evaluation- loss: 0.691826 acc: 0.5312\n",
      "Epoch[17/50] Iteration[680]-loss: 0.676185 acc: 0.6256\n",
      "Evaluation- loss: 0.678905 acc: 0.6250\n",
      "Epoch[17/50] Iteration[700]-loss: 0.676766 acc: 0.5891\n",
      "Evaluation- loss: 0.670227 acc: 0.6250\n",
      "Epoch[18/50] Iteration[720]-loss: 0.682403 acc: 0.5975\n",
      "Evaluation- loss: 0.681273 acc: 0.5781\n",
      "Epoch[18/50] Iteration[740]-loss: 0.677124 acc: 0.5828\n",
      "Evaluation- loss: 0.697492 acc: 0.5312\n",
      "Epoch[19/50] Iteration[760]-loss: 0.682658 acc: 0.5487\n",
      "Evaluation- loss: 0.695286 acc: 0.4688\n",
      "Epoch[19/50] Iteration[780]-loss: 0.674678 acc: 0.6234\n",
      "Evaluation- loss: 0.702895 acc: 0.3750\n",
      "Epoch[20/50] Iteration[800]-loss: 0.685718 acc: 0.5891\n",
      "Evaluation- loss: 0.695994 acc: 0.3750\n",
      "Epoch[20/50] Iteration[820]-loss: 0.687110 acc: 0.5344\n",
      "Evaluation- loss: 0.693098 acc: 0.5156\n",
      "Epoch[21/50] Iteration[840]-loss: 0.681364 acc: 0.5553\n",
      "Evaluation- loss: 0.702742 acc: 0.4844\n",
      "Epoch[21/50] Iteration[860]-loss: 0.676401 acc: 0.6219\n",
      "Evaluation- loss: 0.691405 acc: 0.5312\n",
      "Epoch[22/50] Iteration[880]-loss: 0.684051 acc: 0.5622\n",
      "Evaluation- loss: 0.779335 acc: 0.4219\n",
      "Epoch[22/50] Iteration[900]-loss: 0.697582 acc: 0.5312\n",
      "Evaluation- loss: 0.704720 acc: 0.4219\n",
      "Epoch[23/50] Iteration[920]-loss: 0.684039 acc: 0.5300\n",
      "Evaluation- loss: 0.680890 acc: 0.5781\n",
      "Epoch[23/50] Iteration[940]-loss: 0.685385 acc: 0.5516\n"
     ]
    }
   ],
   "source": [
    "Gridtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob('./trained_task2/rs/?*.model'):\n",
    "    checkpoint = torch.load(f)\n",
    "    testD = dset(tt, dt)\n",
    "    testloader = load_data(testD, batch_size = 32, num_workers = 1)\n",
    "    model = classify(100,100).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    #model.load_state_dict(torch.load('prediction.model'))\n",
    "    _, _ ,p,d,r = evaluate(testloader, model)\n",
    "###Evaluation- loss: 0.825200 acc: 0.7105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (torch.max(p, 1)   )[1] #.view(decision.size()).data == decision.data)\n",
    "# acc = (pred.item()/decision.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1], device='cuda:7')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:7')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = r.cpu().detach().numpy()\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "act_embedded = TSNE(n_components=2).fit_transform(act)\n",
    "act_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efda1191390>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "# co = pred.cpu().detach().numpy()\n",
    "# plt.scatter(act_embedded[:,0], act_embedded[:,1], c=co, marker = markers)\n",
    "# ax.set_xlim([-200,200])\n",
    "# ax.set_ylim([-200,200])\n",
    "# plt.show()\n",
    "correct = np.where(pred.cpu().detach().numpy() == d.cpu().detach().numpy())\n",
    "wrong = np.where(pred.cpu().detach().numpy() != d.cpu().detach().numpy())\n",
    "act_correct = act_embedded[correct]\n",
    "act_wrong = act_embedded[wrong]\n",
    "f, ax = plt.subplots(figsize = (3.5,2.5))\n",
    "plt.scatter(act_correct[:,0], act_correct[:,1], marker='o', c=pred.cpu().detach().numpy()[correct])\n",
    "plt.scatter(act_wrong[:,0], act_wrong[:,1], marker='x', c=pred.cpu().detach().numpy()[wrong])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co = pred.cpu().detach().numpy()[correct]\n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iclr2017_test.txt', 'w') as f:\n",
    "    for i in range(len(x_test[1])):\n",
    "        f.write(x_test[1][i].__dict__['TITLE']+'\\t'+(str(pred[i].item())+','+str(d[i].item())))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'batch_size': 32}\n",
    "params = {\n",
    "             'optimizer': 'Adam',\n",
    "             'Type': 'Review+Sentiment',\n",
    "             'Filter_size': '64 on review',\n",
    "             'Dropout': 0.7,\n",
    "             'iteration': str(int(time.time()))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trained_task2/rs/' + params['iteration'] + '.model', 'wb') as f:\n",
    "                        torch.save(checkpoint, f)\n",
    "with open('./trained_task2/rs/' + params['iteration'] + '.json', 'w') as f:\n",
    "        json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcdl",
   "language": "python",
   "name": "jcdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
